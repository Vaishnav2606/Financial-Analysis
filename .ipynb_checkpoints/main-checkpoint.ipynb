{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f53e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import gym_anytrading\n",
    "from gym_anytrading.envs import StocksEnv\n",
    "from finta import TA\n",
    "from numba import jit, cuda\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNLSTM, Activation, LSTM\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8f3e3",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d23719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-13</th>\n",
       "      <td>318.45</td>\n",
       "      <td>338.90</td>\n",
       "      <td>318.45</td>\n",
       "      <td>336.90</td>\n",
       "      <td>41045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-14</th>\n",
       "      <td>335.00</td>\n",
       "      <td>338.95</td>\n",
       "      <td>330.50</td>\n",
       "      <td>332.90</td>\n",
       "      <td>26577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-15</th>\n",
       "      <td>333.90</td>\n",
       "      <td>340.75</td>\n",
       "      <td>326.55</td>\n",
       "      <td>331.45</td>\n",
       "      <td>25275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-16</th>\n",
       "      <td>333.60</td>\n",
       "      <td>337.00</td>\n",
       "      <td>322.90</td>\n",
       "      <td>327.55</td>\n",
       "      <td>13868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-17</th>\n",
       "      <td>327.50</td>\n",
       "      <td>328.30</td>\n",
       "      <td>313.65</td>\n",
       "      <td>319.80</td>\n",
       "      <td>16554.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-20</th>\n",
       "      <td>315.00</td>\n",
       "      <td>315.00</td>\n",
       "      <td>301.10</td>\n",
       "      <td>302.85</td>\n",
       "      <td>32760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-21</th>\n",
       "      <td>301.55</td>\n",
       "      <td>319.40</td>\n",
       "      <td>301.55</td>\n",
       "      <td>317.35</td>\n",
       "      <td>13643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-22</th>\n",
       "      <td>321.55</td>\n",
       "      <td>326.75</td>\n",
       "      <td>317.45</td>\n",
       "      <td>324.85</td>\n",
       "      <td>6333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-23</th>\n",
       "      <td>326.35</td>\n",
       "      <td>329.70</td>\n",
       "      <td>319.00</td>\n",
       "      <td>321.75</td>\n",
       "      <td>10372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-24</th>\n",
       "      <td>322.55</td>\n",
       "      <td>323.45</td>\n",
       "      <td>318.60</td>\n",
       "      <td>320.90</td>\n",
       "      <td>12265.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close   Volume\n",
       "Date                                               \n",
       "2021-12-13  318.45  338.90  318.45  336.90  41045.0\n",
       "2021-12-14  335.00  338.95  330.50  332.90  26577.0\n",
       "2021-12-15  333.90  340.75  326.55  331.45  25275.0\n",
       "2021-12-16  333.60  337.00  322.90  327.55  13868.0\n",
       "2021-12-17  327.50  328.30  313.65  319.80  16554.0\n",
       "2021-12-20  315.00  315.00  301.10  302.85  32760.0\n",
       "2021-12-21  301.55  319.40  301.55  317.35  13643.0\n",
       "2021-12-22  321.55  326.75  317.45  324.85   6333.0\n",
       "2021-12-23  326.35  329.70  319.00  321.75  10372.0\n",
       "2021-12-24  322.55  323.45  318.60  320.90  12265.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"JINDAL.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.sort_values('Date',ascending=True,inplace=True)\n",
    "df.set_index('Date',inplace=True)\n",
    "df['Volume'] = df['Volume'].apply(lambda x: float(x.replace(',','')))\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18c72bc",
   "metadata": {},
   "source": [
    "# Adding Custom Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf2122b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>OBV</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_SIGNAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-13</th>\n",
       "      <td>318.45</td>\n",
       "      <td>338.90</td>\n",
       "      <td>318.45</td>\n",
       "      <td>336.90</td>\n",
       "      <td>41045.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-14</th>\n",
       "      <td>335.00</td>\n",
       "      <td>338.95</td>\n",
       "      <td>330.50</td>\n",
       "      <td>332.90</td>\n",
       "      <td>26577.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-26577.0</td>\n",
       "      <td>-0.089744</td>\n",
       "      <td>-0.049858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-15</th>\n",
       "      <td>333.90</td>\n",
       "      <td>340.75</td>\n",
       "      <td>326.55</td>\n",
       "      <td>331.45</td>\n",
       "      <td>25275.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-51852.0</td>\n",
       "      <td>-0.159316</td>\n",
       "      <td>-0.094717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-16</th>\n",
       "      <td>333.60</td>\n",
       "      <td>337.00</td>\n",
       "      <td>322.90</td>\n",
       "      <td>327.55</td>\n",
       "      <td>13868.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-65720.0</td>\n",
       "      <td>-0.327862</td>\n",
       "      <td>-0.173696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-17</th>\n",
       "      <td>327.50</td>\n",
       "      <td>328.30</td>\n",
       "      <td>313.65</td>\n",
       "      <td>319.80</td>\n",
       "      <td>16554.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-82274.0</td>\n",
       "      <td>-0.720935</td>\n",
       "      <td>-0.336487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-20</th>\n",
       "      <td>315.00</td>\n",
       "      <td>315.00</td>\n",
       "      <td>301.10</td>\n",
       "      <td>302.85</td>\n",
       "      <td>32760.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-115034.0</td>\n",
       "      <td>-1.668467</td>\n",
       "      <td>-0.697528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-21</th>\n",
       "      <td>301.55</td>\n",
       "      <td>319.40</td>\n",
       "      <td>301.55</td>\n",
       "      <td>317.35</td>\n",
       "      <td>13643.0</td>\n",
       "      <td>33.041870</td>\n",
       "      <td>-101391.0</td>\n",
       "      <td>-1.590514</td>\n",
       "      <td>-0.923519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-22</th>\n",
       "      <td>321.55</td>\n",
       "      <td>326.75</td>\n",
       "      <td>317.45</td>\n",
       "      <td>324.85</td>\n",
       "      <td>6333.0</td>\n",
       "      <td>43.450050</td>\n",
       "      <td>-95058.0</td>\n",
       "      <td>-1.155973</td>\n",
       "      <td>-0.979382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-23</th>\n",
       "      <td>326.35</td>\n",
       "      <td>329.70</td>\n",
       "      <td>319.00</td>\n",
       "      <td>321.75</td>\n",
       "      <td>10372.0</td>\n",
       "      <td>40.638207</td>\n",
       "      <td>-105430.0</td>\n",
       "      <td>-0.991275</td>\n",
       "      <td>-0.982129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-24</th>\n",
       "      <td>322.55</td>\n",
       "      <td>323.45</td>\n",
       "      <td>318.60</td>\n",
       "      <td>320.90</td>\n",
       "      <td>12265.0</td>\n",
       "      <td>39.876204</td>\n",
       "      <td>-117695.0</td>\n",
       "      <td>-0.903804</td>\n",
       "      <td>-0.964580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>309.35</td>\n",
       "      <td>346.70</td>\n",
       "      <td>309.35</td>\n",
       "      <td>345.55</td>\n",
       "      <td>98272.0</td>\n",
       "      <td>62.081477</td>\n",
       "      <td>-19423.0</td>\n",
       "      <td>0.485322</td>\n",
       "      <td>-0.647350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>349.90</td>\n",
       "      <td>356.85</td>\n",
       "      <td>343.80</td>\n",
       "      <td>345.45</td>\n",
       "      <td>26409.0</td>\n",
       "      <td>61.981468</td>\n",
       "      <td>-45832.0</td>\n",
       "      <td>1.491664</td>\n",
       "      <td>-0.187979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>349.50</td>\n",
       "      <td>349.60</td>\n",
       "      <td>342.80</td>\n",
       "      <td>346.10</td>\n",
       "      <td>8801.0</td>\n",
       "      <td>62.405405</td>\n",
       "      <td>-37031.0</td>\n",
       "      <td>2.254924</td>\n",
       "      <td>0.329024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>348.00</td>\n",
       "      <td>353.85</td>\n",
       "      <td>341.95</td>\n",
       "      <td>343.10</td>\n",
       "      <td>6281.0</td>\n",
       "      <td>59.128278</td>\n",
       "      <td>-43312.0</td>\n",
       "      <td>2.623079</td>\n",
       "      <td>0.808942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>342.50</td>\n",
       "      <td>353.00</td>\n",
       "      <td>342.50</td>\n",
       "      <td>348.80</td>\n",
       "      <td>13088.0</td>\n",
       "      <td>63.093868</td>\n",
       "      <td>-30224.0</td>\n",
       "      <td>3.205503</td>\n",
       "      <td>1.305734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close   Volume        RSI       OBV  \\\n",
       "Date                                                                       \n",
       "2021-12-13  318.45  338.90  318.45  336.90  41045.0   0.000000       0.0   \n",
       "2021-12-14  335.00  338.95  330.50  332.90  26577.0   0.000000  -26577.0   \n",
       "2021-12-15  333.90  340.75  326.55  331.45  25275.0   0.000000  -51852.0   \n",
       "2021-12-16  333.60  337.00  322.90  327.55  13868.0   0.000000  -65720.0   \n",
       "2021-12-17  327.50  328.30  313.65  319.80  16554.0   0.000000  -82274.0   \n",
       "2021-12-20  315.00  315.00  301.10  302.85  32760.0   0.000000 -115034.0   \n",
       "2021-12-21  301.55  319.40  301.55  317.35  13643.0  33.041870 -101391.0   \n",
       "2021-12-22  321.55  326.75  317.45  324.85   6333.0  43.450050  -95058.0   \n",
       "2021-12-23  326.35  329.70  319.00  321.75  10372.0  40.638207 -105430.0   \n",
       "2021-12-24  322.55  323.45  318.60  320.90  12265.0  39.876204 -117695.0   \n",
       "2021-12-27  309.35  346.70  309.35  345.55  98272.0  62.081477  -19423.0   \n",
       "2021-12-28  349.90  356.85  343.80  345.45  26409.0  61.981468  -45832.0   \n",
       "2021-12-29  349.50  349.60  342.80  346.10   8801.0  62.405405  -37031.0   \n",
       "2021-12-30  348.00  353.85  341.95  343.10   6281.0  59.128278  -43312.0   \n",
       "2021-12-31  342.50  353.00  342.50  348.80  13088.0  63.093868  -30224.0   \n",
       "\n",
       "                MACD  MACD_SIGNAL  \n",
       "Date                               \n",
       "2021-12-13  0.000000     0.000000  \n",
       "2021-12-14 -0.089744    -0.049858  \n",
       "2021-12-15 -0.159316    -0.094717  \n",
       "2021-12-16 -0.327862    -0.173696  \n",
       "2021-12-17 -0.720935    -0.336487  \n",
       "2021-12-20 -1.668467    -0.697528  \n",
       "2021-12-21 -1.590514    -0.923519  \n",
       "2021-12-22 -1.155973    -0.979382  \n",
       "2021-12-23 -0.991275    -0.982129  \n",
       "2021-12-24 -0.903804    -0.964580  \n",
       "2021-12-27  0.485322    -0.647350  \n",
       "2021-12-28  1.491664    -0.187979  \n",
       "2021-12-29  2.254924     0.329024  \n",
       "2021-12-30  2.623079     0.808942  \n",
       "2021-12-31  3.205503     1.305734  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RSI'] = TA.RSI(df)\n",
    "df['OBV'] = TA.OBV(df)\n",
    "df['MACD'] = TA.MACD(df)['MACD']\n",
    "df['MACD_SIGNAL'] = TA.MACD(df)['SIGNAL']\n",
    "df.fillna(0,inplace=True)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b312f",
   "metadata": {},
   "source": [
    "# Making a sample environment and testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb9c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('stocks-v0', df=df, frame_bound=(7,150), window_size = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ff56fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: {'total_reward': -0.8999999999999773, 'total_profit': 0.5192820046704716, 'position': 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    n_state, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        print('Info:',info)\n",
    "        break\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece97821",
   "metadata": {},
   "source": [
    "# Making our custom Environment with the indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c97cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_process_data(env):\n",
    "    start = env.frame_bound[0] - env.window_size\n",
    "    end = env.frame_bound[1]\n",
    "    prices = env.df.loc[:, 'Low'].to_numpy()[start:end]\n",
    "    signal_features = env.df.loc[:, ['RSI', 'MACD', 'OBV','Volume', 'Low']].to_numpy()[start:end]\n",
    "    return prices, signal_features\n",
    "\n",
    "class MyStocksEnv(StocksEnv):\n",
    "     _process_data = my_process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c7d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MyStocksEnv(df=df, frame_bound=(7,150), window_size = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0232d3",
   "metadata": {},
   "source": [
    "# Vectorizing the env and training our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f37400",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_maker = lambda: env\n",
    "env = DummyVecEnv([env_maker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f4b08b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1059 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 128  |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 88            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 2             |\n",
      "|    total_timesteps      | 256           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014738552 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.693        |\n",
      "|    explained_variance   | 0.0235        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 191           |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00257      |\n",
      "|    value_loss           | 388           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 68            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 384           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013294676 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.693        |\n",
      "|    explained_variance   | 0.0207        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 94.2          |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.0021       |\n",
      "|    value_loss           | 190           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=500, episode_reward=93.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 88            |\n",
      "|    mean_reward          | 93.1          |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 500           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017917901 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.692        |\n",
      "|    explained_variance   | 0.0488        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 160           |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00134      |\n",
      "|    value_loss           | 325           |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 59  |\n",
      "|    iterations      | 4   |\n",
      "|    time_elapsed    | 8   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 59            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 640           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.3146465e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.691        |\n",
      "|    explained_variance   | 0.0516        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 167           |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | 1.32e-05      |\n",
      "|    value_loss           | 336           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 60            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 12            |\n",
      "|    total_timesteps      | 768           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8422026e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.691        |\n",
      "|    explained_variance   | 0.0437        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 295           |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.000602     |\n",
      "|    value_loss           | 596           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 60            |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 896           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2121705e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.69         |\n",
      "|    explained_variance   | 0.0693        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 144           |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.000524     |\n",
      "|    value_loss           | 292           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=1000, episode_reward=81.45 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 81.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.47703e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.69       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 409         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 831         |\n",
      "-----------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 59   |\n",
      "|    iterations      | 8    |\n",
      "|    time_elapsed    | 17   |\n",
      "|    total_timesteps | 1024 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 1152          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018341234 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.69         |\n",
      "|    explained_variance   | 0.0399        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 210           |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.00116      |\n",
      "|    value_loss           | 421           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 57            |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 1280          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3420743e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.689        |\n",
      "|    explained_variance   | 0.0455        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 155           |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.00103      |\n",
      "|    value_loss           | 313           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 56            |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 1408          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022146665 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.688        |\n",
      "|    explained_variance   | 0.092         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 178           |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.0047       |\n",
      "|    value_loss           | 360           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1500, episode_reward=-0.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | -0.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004971232 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.689       |\n",
      "|    explained_variance   | 0.0559       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    value_loss           | 251          |\n",
      "------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 56   |\n",
      "|    iterations      | 12   |\n",
      "|    time_elapsed    | 27   |\n",
      "|    total_timesteps | 1536 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 55            |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 30            |\n",
      "|    total_timesteps      | 1664          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022172811 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.69         |\n",
      "|    explained_variance   | 0.218         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 152           |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.000121     |\n",
      "|    value_loss           | 307           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 32            |\n",
      "|    total_timesteps      | 1792          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011118036 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.69         |\n",
      "|    explained_variance   | 0.0941        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 251           |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.00168      |\n",
      "|    value_loss           | 509           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 55            |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 34            |\n",
      "|    total_timesteps      | 1920          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010342989 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.691        |\n",
      "|    explained_variance   | 0.211         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 149           |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.00126      |\n",
      "|    value_loss           | 302           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=-0.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 88            |\n",
      "|    mean_reward          | -0.1          |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 2000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010846602 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.69         |\n",
      "|    explained_variance   | 0.231         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 119           |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.000591     |\n",
      "|    value_loss           | 245           |\n",
      "-------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 55   |\n",
      "|    iterations      | 16   |\n",
      "|    time_elapsed    | 37   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 2176         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.534889e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.689       |\n",
      "|    explained_variance   | 0.153        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 274          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.000718    |\n",
      "|    value_loss           | 553          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 55            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 41            |\n",
      "|    total_timesteps      | 2304          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0389445e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.689        |\n",
      "|    explained_variance   | 0.227         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 297           |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.000606     |\n",
      "|    value_loss           | 603           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 55            |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 44            |\n",
      "|    total_timesteps      | 2432          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4718622e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.689        |\n",
      "|    explained_variance   | 0.15          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 505           |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000633     |\n",
      "|    value_loss           | 1.02e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=2500, episode_reward=43.40 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 43.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007995602 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.689       |\n",
      "|    explained_variance   | 0.093        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 63.8         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 54   |\n",
      "|    iterations      | 20   |\n",
      "|    time_elapsed    | 46   |\n",
      "|    total_timesteps | 2560 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 2688         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022788164 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.686       |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 170          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    value_loss           | 346          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 2816         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021791668 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.681       |\n",
      "|    explained_variance   | 0.0564       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 230          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    value_loss           | 468          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 2944         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003187575 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.675       |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | 0.000294     |\n",
      "|    value_loss           | 248          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=102.15 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 102          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005186328 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.672       |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 220          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 448          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 53   |\n",
      "|    iterations      | 24   |\n",
      "|    time_elapsed    | 57   |\n",
      "|    total_timesteps | 3072 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 3200         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005114232 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.664       |\n",
      "|    explained_variance   | 0.232        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 94           |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 53            |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 61            |\n",
      "|    total_timesteps      | 3328          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020328513 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.663        |\n",
      "|    explained_variance   | 0.0778        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 507           |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | 0.00028       |\n",
      "|    value_loss           | 1.04e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 63            |\n",
      "|    total_timesteps      | 3456          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070120906 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.662        |\n",
      "|    explained_variance   | 0.163         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 204           |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -0.00484      |\n",
      "|    value_loss           | 422           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=3500, episode_reward=95.85 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 95.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017513856 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.665       |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 330          |\n",
      "------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 54   |\n",
      "|    iterations      | 28   |\n",
      "|    time_elapsed    | 66   |\n",
      "|    total_timesteps | 3584 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 3712         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012356106 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.676       |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 201          |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 412          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 53            |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 3840          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042949617 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.676        |\n",
      "|    explained_variance   | 0.332         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 316           |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.000749     |\n",
      "|    value_loss           | 648           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 3968         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012733722 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.672       |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 280          |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    value_loss           | 571          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4000, episode_reward=35.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 35.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021668363 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.666       |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 138          |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    value_loss           | 284          |\n",
      "------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 53   |\n",
      "|    iterations      | 32   |\n",
      "|    time_elapsed    | 76   |\n",
      "|    total_timesteps | 4096 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 4224         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010698999 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.655       |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 176          |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    value_loss           | 362          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 4352         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014538562 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.646       |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 265          |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00782     |\n",
      "|    value_loss           | 537          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 4480        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003420957 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.621      |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4500, episode_reward=45.20 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 45.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032639045 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.604       |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    value_loss           | 319          |\n",
      "------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 53   |\n",
      "|    iterations      | 36   |\n",
      "|    time_elapsed    | 86   |\n",
      "|    total_timesteps | 4608 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 4736        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006257448 |\n",
      "|    clip_fraction        | 0.00547     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.604      |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00108    |\n",
      "|    value_loss           | 304         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 4864         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009158035 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.591       |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 57.3         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 92            |\n",
      "|    total_timesteps      | 4992          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038307277 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.597        |\n",
      "|    explained_variance   | 0.411         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 177           |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.00094      |\n",
      "|    value_loss           | 367           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=94.70 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 88            |\n",
      "|    mean_reward          | 94.7          |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 5000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042422675 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.593        |\n",
      "|    explained_variance   | 0.388         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 246           |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.00204      |\n",
      "|    value_loss           | 496           |\n",
      "-------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 53   |\n",
      "|    iterations      | 40   |\n",
      "|    time_elapsed    | 94   |\n",
      "|    total_timesteps | 5120 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 53            |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 97            |\n",
      "|    total_timesteps      | 5248          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00097319554 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.581        |\n",
      "|    explained_variance   | -0.497        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 134           |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | -0.00415      |\n",
      "|    value_loss           | 288           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 5376        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007467773 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5500, episode_reward=41.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 41.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028458699 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.294        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 53   |\n",
      "|    iterations      | 43   |\n",
      "|    time_elapsed    | 102  |\n",
      "|    total_timesteps | 5504 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 5632         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036988924 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.182        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 77.7         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 5760        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003380728 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90.1        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 5888         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021912707 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 73.3         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=51.35 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 51.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010748926 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.538      |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 54   |\n",
      "|    iterations      | 47   |\n",
      "|    time_elapsed    | 111  |\n",
      "|    total_timesteps | 6016 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054025585 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.316        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 273          |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00068     |\n",
      "|    value_loss           | 561          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 115           |\n",
      "|    total_timesteps      | 6272          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021603168 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.565        |\n",
      "|    explained_variance   | 0.267         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 132           |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.00197      |\n",
      "|    value_loss           | 269           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 6400         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018611515 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 66.2         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6500, episode_reward=84.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 84.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023446698 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 153          |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.000413    |\n",
      "|    value_loss           | 319          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 53   |\n",
      "|    iterations      | 51   |\n",
      "|    time_elapsed    | 121  |\n",
      "|    total_timesteps | 6528 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 6656         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016645135 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.586       |\n",
      "|    explained_variance   | 0.00247      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 71.8         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 6784         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009141676 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.576       |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 91.7         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 193          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 53            |\n",
      "|    iterations           | 54            |\n",
      "|    time_elapsed         | 128           |\n",
      "|    total_timesteps      | 6912          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046202308 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.586        |\n",
      "|    explained_variance   | 0.346         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 175           |\n",
      "|    n_updates            | 530           |\n",
      "|    policy_gradient_loss | -0.00308      |\n",
      "|    value_loss           | 359           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=99.85 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 99.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009961287 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.577       |\n",
      "|    explained_variance   | 0.209        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    value_loss           | 269          |\n",
      "------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 53   |\n",
      "|    iterations      | 55   |\n",
      "|    time_elapsed    | 131  |\n",
      "|    total_timesteps | 7040 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 53            |\n",
      "|    iterations           | 56            |\n",
      "|    time_elapsed         | 133           |\n",
      "|    total_timesteps      | 7168          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092653395 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.599        |\n",
      "|    explained_variance   | 0.206         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 256           |\n",
      "|    n_updates            | 550           |\n",
      "|    policy_gradient_loss | -0.00342      |\n",
      "|    value_loss           | 520           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 7296        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001322852 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.605      |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 420         |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    value_loss           | 862         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 7424         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029455791 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.609       |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    value_loss           | 322          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7500, episode_reward=102.15 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 102          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008931933 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.616       |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    value_loss           | 283          |\n",
      "------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 53   |\n",
      "|    iterations      | 59   |\n",
      "|    time_elapsed    | 139  |\n",
      "|    total_timesteps | 7552 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 142           |\n",
      "|    total_timesteps      | 7680          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046606874 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.617        |\n",
      "|    explained_variance   | 0.353         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 175           |\n",
      "|    n_updates            | 590           |\n",
      "|    policy_gradient_loss | -0.00234      |\n",
      "|    value_loss           | 363           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 7808        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001971399 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 7936        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001586193 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.586      |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.9        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=95.85 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 95.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010263345 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.56       |\n",
      "|    explained_variance   | -0.0169     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 242         |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 509         |\n",
      "-----------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 53   |\n",
      "|    iterations      | 63   |\n",
      "|    time_elapsed    | 149  |\n",
      "|    total_timesteps | 8064 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 53            |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095545244 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.555        |\n",
      "|    explained_variance   | 0.41          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 172           |\n",
      "|    n_updates            | 630           |\n",
      "|    policy_gradient_loss | -0.000231     |\n",
      "|    value_loss           | 350           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 154        |\n",
      "|    total_timesteps      | 8320       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00100904 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.544     |\n",
      "|    explained_variance   | 0.498      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 119        |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.00522   |\n",
      "|    value_loss           | 243        |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 66            |\n",
      "|    time_elapsed         | 156           |\n",
      "|    total_timesteps      | 8448          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071582594 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.548        |\n",
      "|    explained_variance   | 0.344         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 39.5          |\n",
      "|    n_updates            | 650           |\n",
      "|    policy_gradient_loss | -0.00597      |\n",
      "|    value_loss           | 86.2          |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=8500, episode_reward=67.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 67.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8500        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010456379 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.545      |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 54   |\n",
      "|    iterations      | 67   |\n",
      "|    time_elapsed    | 158  |\n",
      "|    total_timesteps | 8576 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 68            |\n",
      "|    time_elapsed         | 160           |\n",
      "|    total_timesteps      | 8704          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035788352 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.511        |\n",
      "|    explained_variance   | -0.118        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 178           |\n",
      "|    n_updates            | 670           |\n",
      "|    policy_gradient_loss | -0.0021       |\n",
      "|    value_loss           | 373           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 8832         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012877968 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 140          |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.000916    |\n",
      "|    value_loss           | 296          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 70            |\n",
      "|    time_elapsed         | 165           |\n",
      "|    total_timesteps      | 8960          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032024155 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.558        |\n",
      "|    explained_variance   | 0.427         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 156           |\n",
      "|    n_updates            | 690           |\n",
      "|    policy_gradient_loss | -0.00279      |\n",
      "|    value_loss           | 313           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=7.75 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 7.75        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008407736 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.532      |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 185         |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 54   |\n",
      "|    iterations      | 71   |\n",
      "|    time_elapsed    | 167  |\n",
      "|    total_timesteps | 9088 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002100765 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.514      |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 73            |\n",
      "|    time_elapsed         | 172           |\n",
      "|    total_timesteps      | 9344          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021150219 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.516        |\n",
      "|    explained_variance   | 0.392         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 171           |\n",
      "|    n_updates            | 720           |\n",
      "|    policy_gradient_loss | -0.00218      |\n",
      "|    value_loss           | 345           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 9472         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019179266 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 269          |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 546          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9500, episode_reward=69.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 88            |\n",
      "|    mean_reward          | 69.1          |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 9500          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046800985 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.534        |\n",
      "|    explained_variance   | 0.275         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 352           |\n",
      "|    n_updates            | 740           |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    value_loss           | 712           |\n",
      "-------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 54   |\n",
      "|    iterations      | 75   |\n",
      "|    time_elapsed    | 177  |\n",
      "|    total_timesteps | 9600 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 9728         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007281841 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 201          |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 407          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 9856        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004529326 |\n",
      "|    clip_fraction        | 0.00625     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 257         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    value_loss           | 520         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 9984         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011601464 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.328        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 196          |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 409          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=93.25 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 93.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022597285 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 138          |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00846     |\n",
      "|    value_loss           | 296          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 79    |\n",
      "|    time_elapsed    | 185   |\n",
      "|    total_timesteps | 10112 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009985138 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 241          |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    value_loss           | 491          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 10368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003586744 |\n",
      "|    clip_fraction        | 0.00156     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.548      |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    value_loss           | 400         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 10496        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060548894 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 74.5         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10500, episode_reward=81.40 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 81.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008058414 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.513      |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 83    |\n",
      "|    time_elapsed    | 195   |\n",
      "|    total_timesteps | 10624 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 10752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046094162 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.19         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 136          |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 10880        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031587714 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 263          |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00936     |\n",
      "|    value_loss           | 546          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=81.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 81.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010673085 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 255          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 86    |\n",
      "|    time_elapsed    | 202   |\n",
      "|    total_timesteps | 11008 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 87            |\n",
      "|    time_elapsed         | 204           |\n",
      "|    total_timesteps      | 11136         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092678657 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.527        |\n",
      "|    explained_variance   | 0.269         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 320           |\n",
      "|    n_updates            | 860           |\n",
      "|    policy_gradient_loss | -0.00354      |\n",
      "|    value_loss           | 646           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 11264        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031208838 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 340          |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    value_loss           | 699          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 208          |\n",
      "|    total_timesteps      | 11392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035834124 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.245        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    value_loss           | 344          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11500, episode_reward=78.00 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 78           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007915762 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 286          |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    value_loss           | 599          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 90    |\n",
      "|    time_elapsed    | 211   |\n",
      "|    total_timesteps | 11520 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 11648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005523958 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 217          |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 465          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 11776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030568554 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 91.4         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00761     |\n",
      "|    value_loss           | 186          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 11904        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022186697 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    value_loss           | 329          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=86.25 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 86.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014661849 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 197          |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    value_loss           | 405          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 94    |\n",
      "|    time_elapsed    | 221   |\n",
      "|    total_timesteps | 12032 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 12160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001238903 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.441      |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 215         |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    value_loss           | 452         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 96            |\n",
      "|    time_elapsed         | 226           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070525147 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.458        |\n",
      "|    explained_variance   | 0.581         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 329           |\n",
      "|    n_updates            | 950           |\n",
      "|    policy_gradient_loss | -0.0036       |\n",
      "|    value_loss           | 668           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 12416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009782799 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 246          |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    value_loss           | 511          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12500, episode_reward=77.35 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 77.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023874843 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    value_loss           | 234          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 98    |\n",
      "|    time_elapsed    | 230   |\n",
      "|    total_timesteps | 12544 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 12672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011304162 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.457      |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 344         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007609718 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 12928        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023342504 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 115          |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 238          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=13000, episode_reward=65.55 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 65.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 13000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010275082 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.47       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 482         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 102   |\n",
      "|    time_elapsed    | 239   |\n",
      "|    total_timesteps | 13056 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 13184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002165091 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.455      |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    value_loss           | 418         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 13312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042489935 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 239          |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.00737     |\n",
      "|    value_loss           | 484          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 246          |\n",
      "|    total_timesteps      | 13440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013042488 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 443          |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    value_loss           | 893          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13500, episode_reward=53.40 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 53.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034476444 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 405          |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.00745     |\n",
      "|    value_loss           | 817          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 106   |\n",
      "|    time_elapsed    | 249   |\n",
      "|    total_timesteps | 13568 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 13696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011649596 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 339         |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 690         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011320379 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.467      |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    value_loss           | 549         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 255          |\n",
      "|    total_timesteps      | 13952        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016667489 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 356          |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    value_loss           | 718          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14000, episode_reward=61.95 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 61.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 14000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003830559 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.471      |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 257         |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    value_loss           | 528         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 110   |\n",
      "|    time_elapsed    | 257   |\n",
      "|    total_timesteps | 14080 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 260          |\n",
      "|    total_timesteps      | 14208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012384688 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 187          |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 400          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005290851 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.463      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    value_loss           | 353         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 14464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025006456 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 169          |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    value_loss           | 359          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14500, episode_reward=63.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 63.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020828287 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 366          |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    value_loss           | 740          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 114   |\n",
      "|    time_elapsed    | 267   |\n",
      "|    total_timesteps | 14592 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 270          |\n",
      "|    total_timesteps      | 14720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010309208 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 286          |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 610          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 272          |\n",
      "|    total_timesteps      | 14848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076291016 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 193          |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    value_loss           | 392          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 14976        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023369512 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 350          |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | 0.00183      |\n",
      "|    value_loss           | 706          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=82.40 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 82.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037557282 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 216          |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    value_loss           | 451          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 118   |\n",
      "|    time_elapsed    | 276   |\n",
      "|    total_timesteps | 15104 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 15232       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000678543 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.415      |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 172         |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    value_loss           | 363         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 120        |\n",
      "|    time_elapsed         | 280        |\n",
      "|    total_timesteps      | 15360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00836827 |\n",
      "|    clip_fraction        | 0.0703     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.431     |\n",
      "|    explained_variance   | 0.443      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 167        |\n",
      "|    n_updates            | 1190       |\n",
      "|    policy_gradient_loss | -0.0064    |\n",
      "|    value_loss           | 344        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 15488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014376454 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.414      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    value_loss           | 307         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=15500, episode_reward=66.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 66.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007924957 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 272          |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    value_loss           | 574          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 122   |\n",
      "|    time_elapsed    | 285   |\n",
      "|    total_timesteps | 15616 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 123           |\n",
      "|    time_elapsed         | 287           |\n",
      "|    total_timesteps      | 15744         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062964205 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.398        |\n",
      "|    explained_variance   | 0.544         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 282           |\n",
      "|    n_updates            | 1220          |\n",
      "|    policy_gradient_loss | -0.00379      |\n",
      "|    value_loss           | 569           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 124           |\n",
      "|    time_elapsed         | 290           |\n",
      "|    total_timesteps      | 15872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066704117 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.36         |\n",
      "|    explained_variance   | 0.515         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 313           |\n",
      "|    n_updates            | 1230          |\n",
      "|    policy_gradient_loss | -0.00396      |\n",
      "|    value_loss           | 632           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=85.00 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 88            |\n",
      "|    mean_reward          | 85            |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062430534 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.353        |\n",
      "|    explained_variance   | 0.539         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 356           |\n",
      "|    n_updates            | 1240          |\n",
      "|    policy_gradient_loss | -0.00274      |\n",
      "|    value_loss           | 727           |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 125   |\n",
      "|    time_elapsed    | 293   |\n",
      "|    total_timesteps | 16000 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 296          |\n",
      "|    total_timesteps      | 16128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011346629 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.355       |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 414          |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 832          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 127        |\n",
      "|    time_elapsed         | 298        |\n",
      "|    total_timesteps      | 16256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01795147 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.411     |\n",
      "|    explained_variance   | 0.483      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 273        |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 550        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 128        |\n",
      "|    time_elapsed         | 299        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00329962 |\n",
      "|    clip_fraction        | 0.0164     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.415     |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 245        |\n",
      "|    n_updates            | 1270       |\n",
      "|    policy_gradient_loss | -0.00812   |\n",
      "|    value_loss           | 498        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=16500, episode_reward=77.00 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 77           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014185314 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 351          |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 705          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 129   |\n",
      "|    time_elapsed    | 302   |\n",
      "|    total_timesteps | 16512 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 304          |\n",
      "|    total_timesteps      | 16640        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017221058 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 259          |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 522          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 16768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023410494 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.411      |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 301         |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 610         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 16896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008531721 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.401      |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 181         |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    value_loss           | 366         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=17000, episode_reward=69.00 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 69          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 17000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008501691 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.386      |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 440         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 133   |\n",
      "|    time_elapsed    | 311   |\n",
      "|    total_timesteps | 17024 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 314          |\n",
      "|    total_timesteps      | 17152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013580823 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.368       |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 274          |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 549          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 317          |\n",
      "|    total_timesteps      | 17280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012282017 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.37        |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 592          |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    value_loss           | 1.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 319          |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016628182 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 397          |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 797          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17500, episode_reward=68.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 68.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 17500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015518634 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.39       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 468         |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 946         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 137   |\n",
      "|    time_elapsed    | 321   |\n",
      "|    total_timesteps | 17536 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 323          |\n",
      "|    total_timesteps      | 17664        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034411151 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 376          |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    value_loss           | 758          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 325          |\n",
      "|    total_timesteps      | 17792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038049389 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.34        |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 488          |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    value_loss           | 982          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 17920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004329608 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    value_loss           | 623         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=61.30 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 61.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 18000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012650846 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.373      |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    value_loss           | 372         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 141   |\n",
      "|    time_elapsed    | 330   |\n",
      "|    total_timesteps | 18048 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 18176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005573566 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.393      |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 222         |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 452         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 335          |\n",
      "|    total_timesteps      | 18304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022520109 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 265          |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 537          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 337          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017006686 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.359       |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 475          |\n",
      "|    n_updates            | 1430         |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    value_loss           | 959          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18500, episode_reward=77.00 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 77           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044555487 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.355       |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 445          |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    value_loss           | 896          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 145   |\n",
      "|    time_elapsed    | 340   |\n",
      "|    total_timesteps | 18560 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 343          |\n",
      "|    total_timesteps      | 18688        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041100634 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.361       |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 295          |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    value_loss           | 596          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 18816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010177496 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.392      |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 378         |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    value_loss           | 763         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 148           |\n",
      "|    time_elapsed         | 347           |\n",
      "|    total_timesteps      | 18944         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085489475 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.409        |\n",
      "|    explained_variance   | 0.659         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 219           |\n",
      "|    n_updates            | 1470          |\n",
      "|    policy_gradient_loss | -0.00281      |\n",
      "|    value_loss           | 446           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=19000, episode_reward=68.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 68.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 19000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008014682 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.385      |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    value_loss           | 449         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 149   |\n",
      "|    time_elapsed    | 349   |\n",
      "|    total_timesteps | 19072 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 19200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017091796 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 230         |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 465         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 354          |\n",
      "|    total_timesteps      | 19328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033333243 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.394       |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 224          |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    value_loss           | 463          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 152          |\n",
      "|    time_elapsed         | 356          |\n",
      "|    total_timesteps      | 19456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007898251 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.403       |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 1510         |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    value_loss           | 332          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19500, episode_reward=34.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 34.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019059323 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.385       |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 323          |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    value_loss           | 651          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 153   |\n",
      "|    time_elapsed    | 359   |\n",
      "|    total_timesteps | 19584 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 154          |\n",
      "|    time_elapsed         | 361          |\n",
      "|    total_timesteps      | 19712        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030408863 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.362       |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 282          |\n",
      "|    n_updates            | 1530         |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 570          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 364          |\n",
      "|    total_timesteps      | 19840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018685551 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.356       |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 411          |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    value_loss           | 830          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 19968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004467043 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.378      |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 501         |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    value_loss           | 1.01e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=44.55 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 44.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004002572 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.389      |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 398         |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    value_loss           | 802         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 157   |\n",
      "|    time_elapsed    | 369   |\n",
      "|    total_timesteps | 20096 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 20224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009723941 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.393      |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 406         |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    value_loss           | 818         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 20352       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002570594 |\n",
      "|    clip_fraction        | 0.00391     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 297         |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    value_loss           | 603         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 374          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063664787 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.337       |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 161          |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    value_loss           | 326          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=20500, episode_reward=4.55 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 4.55         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013954786 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.336       |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 219          |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    value_loss           | 442          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 161   |\n",
      "|    time_elapsed    | 377   |\n",
      "|    total_timesteps | 20608 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 162          |\n",
      "|    time_elapsed         | 379          |\n",
      "|    total_timesteps      | 20736        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041746614 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.342       |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 190          |\n",
      "|    n_updates            | 1610         |\n",
      "|    policy_gradient_loss | -0.00734     |\n",
      "|    value_loss           | 390          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 163          |\n",
      "|    time_elapsed         | 382          |\n",
      "|    total_timesteps      | 20864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028365436 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.319       |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 275          |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    value_loss           | 557          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 384         |\n",
      "|    total_timesteps      | 20992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011206445 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 451         |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 917         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=21000, episode_reward=32.55 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 88            |\n",
      "|    mean_reward          | 32.6          |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 21000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078209955 |\n",
      "|    clip_fraction        | 0.00234       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.327        |\n",
      "|    explained_variance   | 0.581         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 557           |\n",
      "|    n_updates            | 1640          |\n",
      "|    policy_gradient_loss | -0.00527      |\n",
      "|    value_loss           | 1.12e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 165   |\n",
      "|    time_elapsed    | 387   |\n",
      "|    total_timesteps | 21120 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 21248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002437575 |\n",
      "|    clip_fraction        | 0.00703     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 372         |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    value_loss           | 758         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 21376       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005561707 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 250         |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 509         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=21500, episode_reward=34.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 34.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 21500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024764074 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 400         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 168   |\n",
      "|    time_elapsed    | 394   |\n",
      "|    total_timesteps | 21504 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 169          |\n",
      "|    time_elapsed         | 396          |\n",
      "|    total_timesteps      | 21632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073536397 |\n",
      "|    clip_fraction        | 0.0711       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.339       |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 540          |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | 0.00706      |\n",
      "|    value_loss           | 1.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 398          |\n",
      "|    total_timesteps      | 21760        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019375365 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.335       |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 278          |\n",
      "|    n_updates            | 1690         |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    value_loss           | 572          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 171          |\n",
      "|    time_elapsed         | 400          |\n",
      "|    total_timesteps      | 21888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025387409 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.347       |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 307          |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 617          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=22000, episode_reward=72.75 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 72.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 22000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061064856 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.352       |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 248          |\n",
      "|    n_updates            | 1710         |\n",
      "|    policy_gradient_loss | -0.00989     |\n",
      "|    value_loss           | 500          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 172   |\n",
      "|    time_elapsed    | 403   |\n",
      "|    total_timesteps | 22016 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 22144       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007215695 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 22272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011575713 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 263         |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    value_loss           | 532         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 410          |\n",
      "|    total_timesteps      | 22400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018657979 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.299       |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 598          |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    value_loss           | 1.2e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=22500, episode_reward=68.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 68.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 22500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021341057 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.315       |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 542          |\n",
      "|    n_updates            | 1750         |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    value_loss           | 1.09e+03     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 176   |\n",
      "|    time_elapsed    | 412   |\n",
      "|    total_timesteps | 22528 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 415          |\n",
      "|    total_timesteps      | 22656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026603946 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.324       |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 544          |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.09e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 22784       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004207195 |\n",
      "|    clip_fraction        | 0.00937     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 410         |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    value_loss           | 829         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 418          |\n",
      "|    total_timesteps      | 22912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047349213 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.32        |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 378          |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    value_loss           | 761          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=23000, episode_reward=48.15 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 48.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 23000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018428483 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.294       |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 303          |\n",
      "|    n_updates            | 1790         |\n",
      "|    policy_gradient_loss | -0.000612    |\n",
      "|    value_loss           | 626          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 180   |\n",
      "|    time_elapsed    | 421   |\n",
      "|    total_timesteps | 23040 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 23168       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009971489 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 23296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007110574 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    value_loss           | 545         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 427         |\n",
      "|    total_timesteps      | 23424       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003544151 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 329         |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    value_loss           | 670         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=23500, episode_reward=85.70 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 85.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 23500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046623927 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.308       |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 265          |\n",
      "|    n_updates            | 1830         |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    value_loss           | 534          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 184   |\n",
      "|    time_elapsed    | 430   |\n",
      "|    total_timesteps | 23552 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 23680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009934696 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 341         |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 686         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 435          |\n",
      "|    total_timesteps      | 23808        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009582343 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.297       |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 494          |\n",
      "|    n_updates            | 1850         |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    value_loss           | 994          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 23936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011743324 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 343         |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 690         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=87.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 87.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 24000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001802508 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 446         |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | 8.4e-05     |\n",
      "|    value_loss           | 899         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 188   |\n",
      "|    time_elapsed    | 440   |\n",
      "|    total_timesteps | 24064 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 24192       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017163614 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 317         |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 646         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 24320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004859527 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 347         |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    value_loss           | 700         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 446          |\n",
      "|    total_timesteps      | 24448        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013267312 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.323       |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 253          |\n",
      "|    n_updates            | 1900         |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 512          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=24500, episode_reward=68.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 68.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 24500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034456917 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.313       |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 281          |\n",
      "|    n_updates            | 1910         |\n",
      "|    policy_gradient_loss | -0.00935     |\n",
      "|    value_loss           | 572          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 192   |\n",
      "|    time_elapsed    | 448   |\n",
      "|    total_timesteps | 24576 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 193          |\n",
      "|    time_elapsed         | 451          |\n",
      "|    total_timesteps      | 24704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051709274 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.302       |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 1920         |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 327          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 453          |\n",
      "|    total_timesteps      | 24832        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015125249 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.273       |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 343          |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    value_loss           | 702          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 456          |\n",
      "|    total_timesteps      | 24960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005884182 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.258       |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 511          |\n",
      "|    n_updates            | 1940         |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    value_loss           | 1.03e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=65.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 65.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 25000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013491958 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.271       |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 510          |\n",
      "|    n_updates            | 1950         |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 196   |\n",
      "|    time_elapsed    | 459   |\n",
      "|    total_timesteps | 25088 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 461          |\n",
      "|    total_timesteps      | 25216        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060516596 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.273       |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 497          |\n",
      "|    n_updates            | 1960         |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    value_loss           | 998          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 198          |\n",
      "|    time_elapsed         | 464          |\n",
      "|    total_timesteps      | 25344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032568332 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.303       |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 433          |\n",
      "|    n_updates            | 1970         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 871          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 466          |\n",
      "|    total_timesteps      | 25472        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042985245 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.293       |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 437          |\n",
      "|    n_updates            | 1980         |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    value_loss           | 881          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=25500, episode_reward=77.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 77.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 25500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017816268 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 351         |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 711         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 200   |\n",
      "|    time_elapsed    | 468   |\n",
      "|    total_timesteps | 25600 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 201          |\n",
      "|    time_elapsed         | 470          |\n",
      "|    total_timesteps      | 25728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018099381 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.309       |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 368          |\n",
      "|    n_updates            | 2000         |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 741          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 472          |\n",
      "|    total_timesteps      | 25856        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049588303 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.313       |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 314          |\n",
      "|    n_updates            | 2010         |\n",
      "|    policy_gradient_loss | -0.00799     |\n",
      "|    value_loss           | 631          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 475          |\n",
      "|    total_timesteps      | 25984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026822896 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.316       |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 281          |\n",
      "|    n_updates            | 2020         |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 570          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=26000, episode_reward=83.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 83          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 26000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006788723 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 408         |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    value_loss           | 853         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 204   |\n",
      "|    time_elapsed    | 477   |\n",
      "|    total_timesteps | 26112 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 26240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010744016 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 443         |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    value_loss           | 903         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 206          |\n",
      "|    time_elapsed         | 482          |\n",
      "|    total_timesteps      | 26368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038769848 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.254       |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 463          |\n",
      "|    n_updates            | 2050         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 932          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 26496       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002531476 |\n",
      "|    clip_fraction        | 0.00781     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 323         |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    value_loss           | 652         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=26500, episode_reward=78.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 78.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 26500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043050405 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.291       |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 469          |\n",
      "|    n_updates            | 2070         |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    value_loss           | 943          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 208   |\n",
      "|    time_elapsed    | 487   |\n",
      "|    total_timesteps | 26624 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 209          |\n",
      "|    time_elapsed         | 489          |\n",
      "|    total_timesteps      | 26752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048156674 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.293       |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 536          |\n",
      "|    n_updates            | 2080         |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    value_loss           | 1.08e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 26880       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007702481 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 407         |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    value_loss           | 833         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=27000, episode_reward=86.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 86.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 27000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017829698 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.29        |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 373          |\n",
      "|    n_updates            | 2100         |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    value_loss           | 761          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 211   |\n",
      "|    time_elapsed    | 493   |\n",
      "|    total_timesteps | 27008 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 495         |\n",
      "|    total_timesteps      | 27136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004633862 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 263         |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    value_loss           | 528         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 27264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018064717 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 229         |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 462         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 214          |\n",
      "|    time_elapsed         | 500          |\n",
      "|    total_timesteps      | 27392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026287842 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.295       |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 322          |\n",
      "|    n_updates            | 2130         |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 655          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=27500, episode_reward=82.75 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 82.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 27500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009430519 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.251       |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 512          |\n",
      "|    n_updates            | 2140         |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 215   |\n",
      "|    time_elapsed    | 502   |\n",
      "|    total_timesteps | 27520 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 216          |\n",
      "|    time_elapsed         | 505          |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018715404 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.238       |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 498          |\n",
      "|    n_updates            | 2150         |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 1e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 217          |\n",
      "|    time_elapsed         | 507          |\n",
      "|    total_timesteps      | 27776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030804877 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.267       |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 580          |\n",
      "|    n_updates            | 2160         |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    value_loss           | 1.17e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 27904       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002335799 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 416         |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 836         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=28000, episode_reward=79.95 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 79.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 28000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057984805 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.278       |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 593          |\n",
      "|    n_updates            | 2180         |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    value_loss           | 1.19e+03     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 219   |\n",
      "|    time_elapsed    | 512   |\n",
      "|    total_timesteps | 28032 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 514          |\n",
      "|    total_timesteps      | 28160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015983244 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.264       |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 377          |\n",
      "|    n_updates            | 2190         |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    value_loss           | 762          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 221          |\n",
      "|    time_elapsed         | 516          |\n",
      "|    total_timesteps      | 28288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074595036 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.269       |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 336          |\n",
      "|    n_updates            | 2200         |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 677          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 222          |\n",
      "|    time_elapsed         | 518          |\n",
      "|    total_timesteps      | 28416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031414793 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.279       |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 383          |\n",
      "|    n_updates            | 2210         |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    value_loss           | 772          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=28500, episode_reward=79.95 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 79.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 28500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025590917 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.272       |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 295          |\n",
      "|    n_updates            | 2220         |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    value_loss           | 599          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 223   |\n",
      "|    time_elapsed    | 521   |\n",
      "|    total_timesteps | 28544 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 524         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004389845 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    value_loss           | 377         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 526         |\n",
      "|    total_timesteps      | 28800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003459118 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.232      |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 481         |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    value_loss           | 967         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 28928       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007067182 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.22       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 470         |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    value_loss           | 946         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=29000, episode_reward=93.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 93.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 29000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009340569 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 526         |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    value_loss           | 1.06e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 227   |\n",
      "|    time_elapsed    | 531   |\n",
      "|    total_timesteps | 29056 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 228        |\n",
      "|    time_elapsed         | 533        |\n",
      "|    total_timesteps      | 29184      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00977511 |\n",
      "|    clip_fraction        | 0.0523     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.233     |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 497        |\n",
      "|    n_updates            | 2270       |\n",
      "|    policy_gradient_loss | -0.00702   |\n",
      "|    value_loss           | 998        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 29312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008513957 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 493         |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    value_loss           | 991         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 230          |\n",
      "|    time_elapsed         | 537          |\n",
      "|    total_timesteps      | 29440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021717632 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.191       |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 494          |\n",
      "|    n_updates            | 2290         |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    value_loss           | 992          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=29500, episode_reward=56.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 56.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 29500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003072913 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.184      |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    value_loss           | 451         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 231   |\n",
      "|    time_elapsed    | 539   |\n",
      "|    total_timesteps | 29568 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 232          |\n",
      "|    time_elapsed         | 542          |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029644847 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.201       |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 318          |\n",
      "|    n_updates            | 2310         |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    value_loss           | 658          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 544         |\n",
      "|    total_timesteps      | 29824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027884927 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    value_loss           | 384         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 234        |\n",
      "|    time_elapsed         | 547        |\n",
      "|    total_timesteps      | 29952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04034452 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.237     |\n",
      "|    explained_variance   | 0.757      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 198        |\n",
      "|    n_updates            | 2330       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    value_loss           | 401        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=82.75 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 88         |\n",
      "|    mean_reward          | 82.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 30000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01283544 |\n",
      "|    clip_fraction        | 0.0781     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.222     |\n",
      "|    explained_variance   | 0.705      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 350        |\n",
      "|    n_updates            | 2340       |\n",
      "|    policy_gradient_loss | -0.00541   |\n",
      "|    value_loss           | 709        |\n",
      "----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 235   |\n",
      "|    time_elapsed    | 549   |\n",
      "|    total_timesteps | 30080 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 552          |\n",
      "|    total_timesteps      | 30208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033529352 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 538          |\n",
      "|    n_updates            | 2350         |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    value_loss           | 1.08e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 237          |\n",
      "|    time_elapsed         | 554          |\n",
      "|    total_timesteps      | 30336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023101037 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 519          |\n",
      "|    n_updates            | 2360         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 238          |\n",
      "|    time_elapsed         | 556          |\n",
      "|    total_timesteps      | 30464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034292352 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.231       |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 543          |\n",
      "|    n_updates            | 2370         |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    value_loss           | 1.09e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30500, episode_reward=91.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 91.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036735607 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.231       |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 639          |\n",
      "|    n_updates            | 2380         |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    value_loss           | 1.3e+03      |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 239   |\n",
      "|    time_elapsed    | 559   |\n",
      "|    total_timesteps | 30592 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 240          |\n",
      "|    time_elapsed         | 560          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076573333 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.212       |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 416          |\n",
      "|    n_updates            | 2390         |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    value_loss           | 836          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 241          |\n",
      "|    time_elapsed         | 562          |\n",
      "|    total_timesteps      | 30848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043734917 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.195       |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 312          |\n",
      "|    n_updates            | 2400         |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    value_loss           | 630          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 30976       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010207989 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 253         |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    value_loss           | 513         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=31000, episode_reward=87.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 87.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 31000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008292791 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 239         |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    value_loss           | 484         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 243   |\n",
      "|    time_elapsed    | 567   |\n",
      "|    total_timesteps | 31104 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 244          |\n",
      "|    time_elapsed         | 570          |\n",
      "|    total_timesteps      | 31232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048834793 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.24        |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 282          |\n",
      "|    n_updates            | 2430         |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    value_loss           | 575          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 31360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008832831 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.194      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 420         |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    value_loss           | 849         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 31488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004493192 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.175      |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 585         |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=31500, episode_reward=79.95 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 79.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 31500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017146997 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.212      |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 588         |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 247   |\n",
      "|    time_elapsed    | 578   |\n",
      "|    total_timesteps | 31616 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 580          |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015886005 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.221       |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 571          |\n",
      "|    n_updates            | 2470         |\n",
      "|    policy_gradient_loss | 0.000157     |\n",
      "|    value_loss           | 1.15e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 582          |\n",
      "|    total_timesteps      | 31872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006623452 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.236       |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 568          |\n",
      "|    n_updates            | 2480         |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 1.14e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=86.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 86.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011048263 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.223      |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 437         |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    value_loss           | 884         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 250   |\n",
      "|    time_elapsed    | 585   |\n",
      "|    total_timesteps | 32000 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 251          |\n",
      "|    time_elapsed         | 587          |\n",
      "|    total_timesteps      | 32128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008074844 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.214       |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 474          |\n",
      "|    n_updates            | 2500         |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 954          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 32256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011973883 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 240         |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    value_loss           | 487         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 32384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012286527 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.209      |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=32500, episode_reward=83.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 83           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 32500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028853444 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.212       |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 170          |\n",
      "|    n_updates            | 2530         |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 344          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 254   |\n",
      "|    time_elapsed    | 594   |\n",
      "|    total_timesteps | 32512 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 255          |\n",
      "|    time_elapsed         | 596          |\n",
      "|    total_timesteps      | 32640        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011510735 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.18        |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 418          |\n",
      "|    n_updates            | 2540         |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 840          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 256           |\n",
      "|    time_elapsed         | 599           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053763296 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.165        |\n",
      "|    explained_variance   | 0.578         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 525           |\n",
      "|    n_updates            | 2550          |\n",
      "|    policy_gradient_loss | -0.00198      |\n",
      "|    value_loss           | 1.06e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 601         |\n",
      "|    total_timesteps      | 32896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003409014 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.191      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 441         |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    value_loss           | 888         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=33000, episode_reward=84.15 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 88            |\n",
      "|    mean_reward          | 84.1          |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 33000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048536854 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.177        |\n",
      "|    explained_variance   | 0.706         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 408           |\n",
      "|    n_updates            | 2570          |\n",
      "|    policy_gradient_loss | -0.00101      |\n",
      "|    value_loss           | 820           |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 258   |\n",
      "|    time_elapsed    | 604   |\n",
      "|    total_timesteps | 33024 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 606         |\n",
      "|    total_timesteps      | 33152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005376505 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.197      |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 425         |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    value_loss           | 857         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 260          |\n",
      "|    time_elapsed         | 608          |\n",
      "|    total_timesteps      | 33280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002892597 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.19        |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 470          |\n",
      "|    n_updates            | 2590         |\n",
      "|    policy_gradient_loss | 0.000117     |\n",
      "|    value_loss           | 945          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 610         |\n",
      "|    total_timesteps      | 33408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004266698 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.178      |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 377         |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    value_loss           | 760         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=33500, episode_reward=83.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 88         |\n",
      "|    mean_reward          | 83         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 33500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00421135 |\n",
      "|    clip_fraction        | 0.0148     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.207     |\n",
      "|    explained_variance   | 0.724      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 275        |\n",
      "|    n_updates            | 2610       |\n",
      "|    policy_gradient_loss | -0.00337   |\n",
      "|    value_loss           | 553        |\n",
      "----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 262   |\n",
      "|    time_elapsed    | 612   |\n",
      "|    total_timesteps | 33536 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 615          |\n",
      "|    total_timesteps      | 33664        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013344332 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.212       |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 300          |\n",
      "|    n_updates            | 2620         |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    value_loss           | 605          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 264          |\n",
      "|    time_elapsed         | 617          |\n",
      "|    total_timesteps      | 33792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013874939 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.234       |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 210          |\n",
      "|    n_updates            | 2630         |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 429          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 265          |\n",
      "|    time_elapsed         | 619          |\n",
      "|    total_timesteps      | 33920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016612206 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.217       |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 230          |\n",
      "|    n_updates            | 2640         |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    value_loss           | 464          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=34000, episode_reward=83.15 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 83.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 34000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006249896 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.186       |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 390          |\n",
      "|    n_updates            | 2650         |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    value_loss           | 784          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 266   |\n",
      "|    time_elapsed    | 622   |\n",
      "|    total_timesteps | 34048 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 267          |\n",
      "|    time_elapsed         | 624          |\n",
      "|    total_timesteps      | 34176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039000404 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.211       |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 469          |\n",
      "|    n_updates            | 2660         |\n",
      "|    policy_gradient_loss | -0.00916     |\n",
      "|    value_loss           | 948          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 268          |\n",
      "|    time_elapsed         | 627          |\n",
      "|    total_timesteps      | 34304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064800647 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.229       |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 496          |\n",
      "|    n_updates            | 2670         |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    value_loss           | 998          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 269           |\n",
      "|    time_elapsed         | 629           |\n",
      "|    total_timesteps      | 34432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066083437 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.253        |\n",
      "|    explained_variance   | 0.723         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 506           |\n",
      "|    n_updates            | 2680          |\n",
      "|    policy_gradient_loss | -0.000761     |\n",
      "|    value_loss           | 1.02e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=34500, episode_reward=83.15 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 83.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 34500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031657729 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.248       |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 435          |\n",
      "|    n_updates            | 2690         |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    value_loss           | 873          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 270   |\n",
      "|    time_elapsed    | 631   |\n",
      "|    total_timesteps | 34560 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 271          |\n",
      "|    time_elapsed         | 633          |\n",
      "|    total_timesteps      | 34688        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017961897 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.244       |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 377          |\n",
      "|    n_updates            | 2700         |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    value_loss           | 770          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 272          |\n",
      "|    time_elapsed         | 635          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035272252 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.252       |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 304          |\n",
      "|    n_updates            | 2710         |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    value_loss           | 610          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 637          |\n",
      "|    total_timesteps      | 34944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030197855 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.249       |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 255          |\n",
      "|    n_updates            | 2720         |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    value_loss           | 516          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 92          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 35000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010866383 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 285         |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    value_loss           | 574         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 274   |\n",
      "|    time_elapsed    | 640   |\n",
      "|    total_timesteps | 35072 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 35200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003240752 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 334         |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    value_loss           | 673         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 645         |\n",
      "|    total_timesteps      | 35328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004122687 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.199      |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 422         |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    value_loss           | 851         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 277          |\n",
      "|    time_elapsed         | 647          |\n",
      "|    total_timesteps      | 35456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005211488 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 503          |\n",
      "|    n_updates            | 2760         |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    value_loss           | 1.02e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=35500, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 95.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 35500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006229989 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.225       |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 495          |\n",
      "|    n_updates            | 2770         |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    value_loss           | 994          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 278   |\n",
      "|    time_elapsed    | 650   |\n",
      "|    total_timesteps | 35584 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 35712       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001833526 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.248      |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 515         |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 280          |\n",
      "|    time_elapsed         | 654          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021601769 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.254       |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 337          |\n",
      "|    n_updates            | 2790         |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    value_loss           | 682          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 281          |\n",
      "|    time_elapsed         | 656          |\n",
      "|    total_timesteps      | 35968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006435716 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.244       |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 437          |\n",
      "|    n_updates            | 2800         |\n",
      "|    policy_gradient_loss | -0.000849    |\n",
      "|    value_loss           | 890          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=36000, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 95.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 36000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030179983 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.245       |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 313          |\n",
      "|    n_updates            | 2810         |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    value_loss           | 632          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 282   |\n",
      "|    time_elapsed    | 658   |\n",
      "|    total_timesteps | 36096 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 660          |\n",
      "|    total_timesteps      | 36224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049378113 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.25        |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 234          |\n",
      "|    n_updates            | 2820         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 473          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 284          |\n",
      "|    time_elapsed         | 663          |\n",
      "|    total_timesteps      | 36352        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032789747 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.252       |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 2830         |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    value_loss           | 321          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 285          |\n",
      "|    time_elapsed         | 665          |\n",
      "|    total_timesteps      | 36480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039613806 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.244       |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 226          |\n",
      "|    n_updates            | 2840         |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 463          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=36500, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 92          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 36500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000736207 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.197      |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 464         |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    value_loss           | 942         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 286   |\n",
      "|    time_elapsed    | 668   |\n",
      "|    total_timesteps | 36608 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 287          |\n",
      "|    time_elapsed         | 670          |\n",
      "|    total_timesteps      | 36736        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030188689 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.183       |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 492          |\n",
      "|    n_updates            | 2860         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 997          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 288          |\n",
      "|    time_elapsed         | 673          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054342514 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 381          |\n",
      "|    n_updates            | 2870         |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    value_loss           | 768          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 289          |\n",
      "|    time_elapsed         | 675          |\n",
      "|    total_timesteps      | 36992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025761337 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.206       |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 506          |\n",
      "|    n_updates            | 2880         |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.02e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=37000, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 92          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 37000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004852077 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.212      |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 382         |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    value_loss           | 768         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 290   |\n",
      "|    time_elapsed    | 677   |\n",
      "|    total_timesteps | 37120 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 291          |\n",
      "|    time_elapsed         | 679          |\n",
      "|    total_timesteps      | 37248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008838731 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.207       |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 405          |\n",
      "|    n_updates            | 2900         |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 816          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 292          |\n",
      "|    time_elapsed         | 681          |\n",
      "|    total_timesteps      | 37376        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010542567 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.218       |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 387          |\n",
      "|    n_updates            | 2910         |\n",
      "|    policy_gradient_loss | -0.000349    |\n",
      "|    value_loss           | 811          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=37500, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 92           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 37500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013682649 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.231       |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 321          |\n",
      "|    n_updates            | 2920         |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 652          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 293   |\n",
      "|    time_elapsed    | 684   |\n",
      "|    total_timesteps | 37504 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 294          |\n",
      "|    time_elapsed         | 686          |\n",
      "|    total_timesteps      | 37632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025226919 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.22        |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 2930         |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    value_loss           | 377          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 688         |\n",
      "|    total_timesteps      | 37760       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017441293 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.217      |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    value_loss           | 544         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 296          |\n",
      "|    time_elapsed         | 690          |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065673334 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.194       |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 468          |\n",
      "|    n_updates            | 2950         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    value_loss           | 940          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=38000, episode_reward=83.15 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 88            |\n",
      "|    mean_reward          | 83.1          |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 38000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033471873 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.179        |\n",
      "|    explained_variance   | 0.723         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 517           |\n",
      "|    n_updates            | 2960          |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    value_loss           | 1.04e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 297   |\n",
      "|    time_elapsed    | 693   |\n",
      "|    total_timesteps | 38016 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 298          |\n",
      "|    time_elapsed         | 696          |\n",
      "|    total_timesteps      | 38144        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011089239 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.153       |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 385          |\n",
      "|    n_updates            | 2970         |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    value_loss           | 801          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 299           |\n",
      "|    time_elapsed         | 698           |\n",
      "|    total_timesteps      | 38272         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014768331 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.198        |\n",
      "|    explained_variance   | 0.744         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 487           |\n",
      "|    n_updates            | 2980          |\n",
      "|    policy_gradient_loss | -0.000435     |\n",
      "|    value_loss           | 982           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 700          |\n",
      "|    total_timesteps      | 38400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066905385 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.215       |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 481          |\n",
      "|    n_updates            | 2990         |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    value_loss           | 984          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=38500, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 92          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 38500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009983934 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.232      |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 410         |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    value_loss           | 824         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 301   |\n",
      "|    time_elapsed    | 702   |\n",
      "|    total_timesteps | 38528 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 302          |\n",
      "|    time_elapsed         | 704          |\n",
      "|    total_timesteps      | 38656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014270295 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.23        |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 290          |\n",
      "|    n_updates            | 3010         |\n",
      "|    policy_gradient_loss | -0.000895    |\n",
      "|    value_loss           | 585          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 303        |\n",
      "|    time_elapsed         | 706        |\n",
      "|    total_timesteps      | 38784      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01197038 |\n",
      "|    clip_fraction        | 0.0414     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.254     |\n",
      "|    explained_variance   | 0.788      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 310        |\n",
      "|    n_updates            | 3020       |\n",
      "|    policy_gradient_loss | -0.00397   |\n",
      "|    value_loss           | 623        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 304          |\n",
      "|    time_elapsed         | 709          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007335574 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.254       |\n",
      "|    explained_variance   | 0.828        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 200          |\n",
      "|    n_updates            | 3030         |\n",
      "|    policy_gradient_loss | -0.0006      |\n",
      "|    value_loss           | 406          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=39000, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 92          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 39000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009025477 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.256      |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    value_loss           | 452         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 305   |\n",
      "|    time_elapsed    | 712   |\n",
      "|    total_timesteps | 39040 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 714         |\n",
      "|    total_timesteps      | 39168       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006908642 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.228      |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 430         |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    value_loss           | 871         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 307          |\n",
      "|    time_elapsed         | 716          |\n",
      "|    total_timesteps      | 39296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007020687 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.194       |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 367          |\n",
      "|    n_updates            | 3060         |\n",
      "|    policy_gradient_loss | -0.000538    |\n",
      "|    value_loss           | 744          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 308        |\n",
      "|    time_elapsed         | 719        |\n",
      "|    total_timesteps      | 39424      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00200326 |\n",
      "|    clip_fraction        | 0.00391    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.232     |\n",
      "|    explained_variance   | 0.725      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 411        |\n",
      "|    n_updates            | 3070       |\n",
      "|    policy_gradient_loss | -0.00292   |\n",
      "|    value_loss           | 826        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=39500, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 95.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 39500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069424375 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.245       |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 402          |\n",
      "|    n_updates            | 3080         |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    value_loss           | 808          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 309   |\n",
      "|    time_elapsed    | 721   |\n",
      "|    total_timesteps | 39552 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 310          |\n",
      "|    time_elapsed         | 723          |\n",
      "|    total_timesteps      | 39680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059670187 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.25        |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 364          |\n",
      "|    n_updates            | 3090         |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    value_loss           | 733          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 311          |\n",
      "|    time_elapsed         | 725          |\n",
      "|    total_timesteps      | 39808        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030808689 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.232       |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 351          |\n",
      "|    n_updates            | 3100         |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    value_loss           | 707          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 727         |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002709524 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.209      |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 260         |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    value_loss           | 523         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 95.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005544794 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 264         |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    value_loss           | 533         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 313   |\n",
      "|    time_elapsed    | 730   |\n",
      "|    total_timesteps | 40064 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 40192       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010345119 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    value_loss           | 359         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 735         |\n",
      "|    total_timesteps      | 40320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018638236 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 208         |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    value_loss           | 425         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 316          |\n",
      "|    time_elapsed         | 737          |\n",
      "|    total_timesteps      | 40448        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032416945 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.24        |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 345          |\n",
      "|    n_updates            | 3150         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 692          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40500, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 92           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040472453 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.2         |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 496          |\n",
      "|    n_updates            | 3160         |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 999          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 317   |\n",
      "|    time_elapsed    | 739   |\n",
      "|    total_timesteps | 40576 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 318           |\n",
      "|    time_elapsed         | 742           |\n",
      "|    total_timesteps      | 40704         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074401964 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.216        |\n",
      "|    explained_variance   | 0.698         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 371           |\n",
      "|    n_updates            | 3170          |\n",
      "|    policy_gradient_loss | -0.00187      |\n",
      "|    value_loss           | 749           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 319          |\n",
      "|    time_elapsed         | 744          |\n",
      "|    total_timesteps      | 40832        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004663258 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.244       |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 365          |\n",
      "|    n_updates            | 3180         |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 734          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 320          |\n",
      "|    time_elapsed         | 746          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046430402 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.271       |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 389          |\n",
      "|    n_updates            | 3190         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 792          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=41000, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 92           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 41000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014888255 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.269       |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 397          |\n",
      "|    n_updates            | 3200         |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 798          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 321   |\n",
      "|    time_elapsed    | 748   |\n",
      "|    total_timesteps | 41088 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 750         |\n",
      "|    total_timesteps      | 41216       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004441177 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.243      |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 431         |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 870         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 323          |\n",
      "|    time_elapsed         | 752          |\n",
      "|    total_timesteps      | 41344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028176743 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.271       |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 204          |\n",
      "|    n_updates            | 3220         |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 420          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 755         |\n",
      "|    total_timesteps      | 41472       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009000932 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 341         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=41500, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 92          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 41500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007956214 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 336         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 325   |\n",
      "|    time_elapsed    | 758   |\n",
      "|    total_timesteps | 41600 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 760          |\n",
      "|    total_timesteps      | 41728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066175414 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.246       |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 341          |\n",
      "|    n_updates            | 3250         |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 685          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 762         |\n",
      "|    total_timesteps      | 41856       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005137124 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.201      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 370         |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 748         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 328          |\n",
      "|    time_elapsed         | 765          |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035077494 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.21        |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 426          |\n",
      "|    n_updates            | 3270         |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    value_loss           | 860          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=42000, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 92          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 42000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009589751 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 408         |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 820         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 329   |\n",
      "|    time_elapsed    | 767   |\n",
      "|    total_timesteps | 42112 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 330          |\n",
      "|    time_elapsed         | 769          |\n",
      "|    total_timesteps      | 42240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042213704 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.251       |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 455          |\n",
      "|    n_updates            | 3290         |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    value_loss           | 914          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 331          |\n",
      "|    time_elapsed         | 771          |\n",
      "|    total_timesteps      | 42368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060304133 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.241       |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 390          |\n",
      "|    n_updates            | 3300         |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 785          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 332           |\n",
      "|    time_elapsed         | 773           |\n",
      "|    total_timesteps      | 42496         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077965437 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.214        |\n",
      "|    explained_variance   | 0.787         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 405           |\n",
      "|    n_updates            | 3310          |\n",
      "|    policy_gradient_loss | -0.00183      |\n",
      "|    value_loss           | 815           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=42500, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 95.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 42500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015422317 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 229         |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    value_loss           | 461         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 333   |\n",
      "|    time_elapsed    | 776   |\n",
      "|    total_timesteps | 42624 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 778         |\n",
      "|    total_timesteps      | 42752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010077318 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.239      |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 246         |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 510         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 781         |\n",
      "|    total_timesteps      | 42880       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007850034 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 388         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=43000, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 92           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 43000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049773324 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.234       |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 302          |\n",
      "|    n_updates            | 3350         |\n",
      "|    policy_gradient_loss | -0.000679    |\n",
      "|    value_loss           | 607          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 336   |\n",
      "|    time_elapsed    | 783   |\n",
      "|    total_timesteps | 43008 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 337          |\n",
      "|    time_elapsed         | 786          |\n",
      "|    total_timesteps      | 43136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070121414 |\n",
      "|    clip_fraction        | 0.0523       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.196       |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 417          |\n",
      "|    n_updates            | 3360         |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    value_loss           | 855          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 338        |\n",
      "|    time_elapsed         | 788        |\n",
      "|    total_timesteps      | 43264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00217505 |\n",
      "|    clip_fraction        | 0.00937    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.188     |\n",
      "|    explained_variance   | 0.753      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 417        |\n",
      "|    n_updates            | 3370       |\n",
      "|    policy_gradient_loss | -0.00278   |\n",
      "|    value_loss           | 844        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 339          |\n",
      "|    time_elapsed         | 791          |\n",
      "|    total_timesteps      | 43392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019782325 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.216       |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 418          |\n",
      "|    n_updates            | 3380         |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    value_loss           | 845          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=43500, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 95.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 43500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044015325 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.25        |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 432          |\n",
      "|    n_updates            | 3390         |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 868          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 340   |\n",
      "|    time_elapsed    | 793   |\n",
      "|    total_timesteps | 43520 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 341          |\n",
      "|    time_elapsed         | 795          |\n",
      "|    total_timesteps      | 43648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042502135 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.253       |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 382          |\n",
      "|    n_updates            | 3400         |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    value_loss           | 782          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 43776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009297408 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.216      |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 406         |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    value_loss           | 829         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 800         |\n",
      "|    total_timesteps      | 43904       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013144876 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 267         |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    value_loss           | 539         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=44000, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 95.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 44000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036821503 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 257          |\n",
      "|    n_updates            | 3430         |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 521          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 344   |\n",
      "|    time_elapsed    | 802   |\n",
      "|    total_timesteps | 44032 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 805          |\n",
      "|    total_timesteps      | 44160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153686395 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.249       |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 163          |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 331          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 346          |\n",
      "|    time_elapsed         | 807          |\n",
      "|    total_timesteps      | 44288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032968456 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.228       |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 246          |\n",
      "|    n_updates            | 3450         |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 499          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 347          |\n",
      "|    time_elapsed         | 809          |\n",
      "|    total_timesteps      | 44416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008993903 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.191       |\n",
      "|    explained_variance   | 0.766        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 364          |\n",
      "|    n_updates            | 3460         |\n",
      "|    policy_gradient_loss | -0.001       |\n",
      "|    value_loss           | 737          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=44500, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 92           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 44500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015096697 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.194       |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 461          |\n",
      "|    n_updates            | 3470         |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 941          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 348   |\n",
      "|    time_elapsed    | 812   |\n",
      "|    total_timesteps | 44544 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 349           |\n",
      "|    time_elapsed         | 814           |\n",
      "|    total_timesteps      | 44672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031048432 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.223        |\n",
      "|    explained_variance   | 0.745         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 384           |\n",
      "|    n_updates            | 3480          |\n",
      "|    policy_gradient_loss | -0.000979     |\n",
      "|    value_loss           | 771           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 816         |\n",
      "|    total_timesteps      | 44800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004194052 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.233      |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 417         |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    value_loss           | 839         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 351          |\n",
      "|    time_elapsed         | 818          |\n",
      "|    total_timesteps      | 44928        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007006789 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.237       |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 415          |\n",
      "|    n_updates            | 3500         |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 838          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=45000, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 95.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 45000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070802732 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.211       |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 396          |\n",
      "|    n_updates            | 3510         |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    value_loss           | 796          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 352   |\n",
      "|    time_elapsed    | 820   |\n",
      "|    total_timesteps | 45056 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 353          |\n",
      "|    time_elapsed         | 822          |\n",
      "|    total_timesteps      | 45184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056698704 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.245       |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 277          |\n",
      "|    n_updates            | 3520         |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    value_loss           | 563          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 354          |\n",
      "|    time_elapsed         | 825          |\n",
      "|    total_timesteps      | 45312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008983996 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.252       |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 196          |\n",
      "|    n_updates            | 3530         |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    value_loss           | 396          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 827         |\n",
      "|    total_timesteps      | 45440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027221957 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 308         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=45500, episode_reward=84.20 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 84.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 45500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011828755 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 262         |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    value_loss           | 527         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 356   |\n",
      "|    time_elapsed    | 829   |\n",
      "|    total_timesteps | 45568 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 832         |\n",
      "|    total_timesteps      | 45696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005234894 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.212      |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 366         |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    value_loss           | 736         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 358          |\n",
      "|    time_elapsed         | 834          |\n",
      "|    total_timesteps      | 45824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057117036 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.203       |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 445          |\n",
      "|    n_updates            | 3570         |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    value_loss           | 895          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 359          |\n",
      "|    time_elapsed         | 836          |\n",
      "|    total_timesteps      | 45952        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003654654 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.221       |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 368          |\n",
      "|    n_updates            | 3580         |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 739          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=46000, episode_reward=86.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 86.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 46000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010622751 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.237       |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 434          |\n",
      "|    n_updates            | 3590         |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 871          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 360   |\n",
      "|    time_elapsed    | 839   |\n",
      "|    total_timesteps | 46080 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 361           |\n",
      "|    time_elapsed         | 841           |\n",
      "|    total_timesteps      | 46208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077129086 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.25         |\n",
      "|    explained_variance   | 0.794         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 397           |\n",
      "|    n_updates            | 3600          |\n",
      "|    policy_gradient_loss | -0.00199      |\n",
      "|    value_loss           | 801           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 362          |\n",
      "|    time_elapsed         | 843          |\n",
      "|    total_timesteps      | 46336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018683118 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.229       |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 390          |\n",
      "|    n_updates            | 3610         |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 785          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 363          |\n",
      "|    time_elapsed         | 845          |\n",
      "|    total_timesteps      | 46464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010753816 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.237       |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 254          |\n",
      "|    n_updates            | 3620         |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    value_loss           | 515          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=46500, episode_reward=86.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 86.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 46500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005890362 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 276         |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    value_loss           | 557         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 364   |\n",
      "|    time_elapsed    | 848   |\n",
      "|    total_timesteps | 46592 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 850         |\n",
      "|    total_timesteps      | 46720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001284637 |\n",
      "|    clip_fraction        | 0.00937     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 46848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002855921 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    value_loss           | 433         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 367          |\n",
      "|    time_elapsed         | 855          |\n",
      "|    total_timesteps      | 46976        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014713926 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.206       |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 392          |\n",
      "|    n_updates            | 3660         |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 792          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=47000, episode_reward=86.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 86.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 47000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012587365 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.183       |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 389          |\n",
      "|    n_updates            | 3670         |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    value_loss           | 782          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 368   |\n",
      "|    time_elapsed    | 858   |\n",
      "|    total_timesteps | 47104 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 369           |\n",
      "|    time_elapsed         | 860           |\n",
      "|    total_timesteps      | 47232         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096528186 |\n",
      "|    clip_fraction        | 0.00391       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.2          |\n",
      "|    explained_variance   | 0.772         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 407           |\n",
      "|    n_updates            | 3680          |\n",
      "|    policy_gradient_loss | -0.00234      |\n",
      "|    value_loss           | 817           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 863         |\n",
      "|    total_timesteps      | 47360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008262526 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.216      |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 419         |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    value_loss           | 842         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 864         |\n",
      "|    total_timesteps      | 47488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002937249 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.216      |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 332         |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 668         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=47500, episode_reward=78.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 78.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 47500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003236822 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.206      |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 414         |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    value_loss           | 832         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 372   |\n",
      "|    time_elapsed    | 867   |\n",
      "|    total_timesteps | 47616 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 869         |\n",
      "|    total_timesteps      | 47744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017285164 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.19       |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 253         |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    value_loss           | 516         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 374          |\n",
      "|    time_elapsed         | 871          |\n",
      "|    total_timesteps      | 47872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011034801 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 275          |\n",
      "|    n_updates            | 3730         |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    value_loss           | 558          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=32.55 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 32.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015219476 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.187      |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 202         |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    value_loss           | 409         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 375   |\n",
      "|    time_elapsed    | 874   |\n",
      "|    total_timesteps | 48000 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 376          |\n",
      "|    time_elapsed         | 877          |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012736642 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.183       |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 159          |\n",
      "|    n_updates            | 3750         |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    value_loss           | 324          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 879         |\n",
      "|    total_timesteps      | 48256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004726059 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.156      |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 378         |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 762         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 378          |\n",
      "|    time_elapsed         | 881          |\n",
      "|    total_timesteps      | 48384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016434754 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 476          |\n",
      "|    n_updates            | 3770         |\n",
      "|    policy_gradient_loss | -0.000343    |\n",
      "|    value_loss           | 957          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=48500, episode_reward=56.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 88            |\n",
      "|    mean_reward          | 56            |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 48500         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068046246 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.18         |\n",
      "|    explained_variance   | 0.737         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 421           |\n",
      "|    n_updates            | 3780          |\n",
      "|    policy_gradient_loss | -0.00156      |\n",
      "|    value_loss           | 846           |\n",
      "-------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 379   |\n",
      "|    time_elapsed    | 884   |\n",
      "|    total_timesteps | 48512 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 380          |\n",
      "|    time_elapsed         | 886          |\n",
      "|    total_timesteps      | 48640        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028695583 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.188       |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 415          |\n",
      "|    n_updates            | 3790         |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    value_loss           | 835          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 381          |\n",
      "|    time_elapsed         | 888          |\n",
      "|    total_timesteps      | 48768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032264094 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.194       |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 391          |\n",
      "|    n_updates            | 3800         |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    value_loss           | 786          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 890          |\n",
      "|    total_timesteps      | 48896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016512768 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 418          |\n",
      "|    n_updates            | 3810         |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    value_loss           | 840          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=49000, episode_reward=57.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 57.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 49000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027539614 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.168       |\n",
      "|    explained_variance   | 0.812        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 202          |\n",
      "|    n_updates            | 3820         |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 405          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 383   |\n",
      "|    time_elapsed    | 892   |\n",
      "|    total_timesteps | 49024 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 384          |\n",
      "|    time_elapsed         | 895          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011346634 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.196       |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 237          |\n",
      "|    n_updates            | 3830         |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    value_loss           | 490          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 897          |\n",
      "|    total_timesteps      | 49280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046024723 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.209       |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 180          |\n",
      "|    n_updates            | 3840         |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 377          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 900         |\n",
      "|    total_timesteps      | 49408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003962875 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.215      |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    value_loss           | 330         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=49500, episode_reward=75.50 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 75.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 49500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012177476 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.182       |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 322          |\n",
      "|    n_updates            | 3860         |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 652          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 387   |\n",
      "|    time_elapsed    | 902   |\n",
      "|    total_timesteps | 49536 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 388          |\n",
      "|    time_elapsed         | 905          |\n",
      "|    total_timesteps      | 49664        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003122855 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.163       |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 397          |\n",
      "|    n_updates            | 3870         |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    value_loss           | 799          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 907         |\n",
      "|    total_timesteps      | 49792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008044059 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.184      |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 363         |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    value_loss           | 730         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 390          |\n",
      "|    time_elapsed         | 909          |\n",
      "|    total_timesteps      | 49920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066880044 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.19        |\n",
      "|    explained_variance   | 0.81         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 405          |\n",
      "|    n_updates            | 3890         |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    value_loss           | 814          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=55.15 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 55.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070117554 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.195       |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 381          |\n",
      "|    n_updates            | 3900         |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    value_loss           | 765          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 391   |\n",
      "|    time_elapsed    | 912   |\n",
      "|    total_timesteps | 50048 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 392          |\n",
      "|    time_elapsed         | 914          |\n",
      "|    total_timesteps      | 50176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013827623 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.173       |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 407          |\n",
      "|    n_updates            | 3910         |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    value_loss           | 835          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 393          |\n",
      "|    time_elapsed         | 916          |\n",
      "|    total_timesteps      | 50304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023612452 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.156       |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 310          |\n",
      "|    n_updates            | 3920         |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    value_loss           | 625          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 394          |\n",
      "|    time_elapsed         | 918          |\n",
      "|    total_timesteps      | 50432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049818326 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.204       |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 216          |\n",
      "|    n_updates            | 3930         |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    value_loss           | 435          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50500, episode_reward=73.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 73.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006474265 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.213      |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 395   |\n",
      "|    time_elapsed    | 921   |\n",
      "|    total_timesteps | 50560 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 396          |\n",
      "|    time_elapsed         | 924          |\n",
      "|    total_timesteps      | 50688        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015912824 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.23        |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 132          |\n",
      "|    n_updates            | 3950         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 281          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 397          |\n",
      "|    time_elapsed         | 926          |\n",
      "|    total_timesteps      | 50816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037961786 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 264          |\n",
      "|    n_updates            | 3960         |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    value_loss           | 542          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 398          |\n",
      "|    time_elapsed         | 928          |\n",
      "|    total_timesteps      | 50944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030055204 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.188       |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 404          |\n",
      "|    n_updates            | 3970         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 814          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=51000, episode_reward=80.25 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 80.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 51000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039028742 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 423          |\n",
      "|    n_updates            | 3980         |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    value_loss           | 852          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 399   |\n",
      "|    time_elapsed    | 931   |\n",
      "|    total_timesteps | 51072 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 933         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003949409 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 366         |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 741         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 401          |\n",
      "|    time_elapsed         | 936          |\n",
      "|    total_timesteps      | 51328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042238636 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.234       |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 403          |\n",
      "|    n_updates            | 4000         |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 810          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 402          |\n",
      "|    time_elapsed         | 937          |\n",
      "|    total_timesteps      | 51456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018185824 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.214       |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 324          |\n",
      "|    n_updates            | 4010         |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    value_loss           | 654          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=51500, episode_reward=81.85 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 81.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 51500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003177725 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.177      |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 319         |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    value_loss           | 642         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 403   |\n",
      "|    time_elapsed    | 940   |\n",
      "|    total_timesteps | 51584 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 942         |\n",
      "|    total_timesteps      | 51712       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009517264 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 209         |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    value_loss           | 421         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 944         |\n",
      "|    total_timesteps      | 51840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013617968 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    value_loss           | 445         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 406         |\n",
      "|    time_elapsed         | 947         |\n",
      "|    total_timesteps      | 51968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033751443 |\n",
      "|    clip_fraction        | 0.0719      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.239      |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 4050        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 342         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 88         |\n",
      "|    mean_reward          | 92         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 52000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03113645 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.271     |\n",
      "|    explained_variance   | 0.852      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 261        |\n",
      "|    n_updates            | 4060       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    value_loss           | 525        |\n",
      "----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 407   |\n",
      "|    time_elapsed    | 949   |\n",
      "|    total_timesteps | 52096 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 408          |\n",
      "|    time_elapsed         | 952          |\n",
      "|    total_timesteps      | 52224        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051895734 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.236       |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 509          |\n",
      "|    n_updates            | 4070         |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 409           |\n",
      "|    time_elapsed         | 954           |\n",
      "|    total_timesteps      | 52352         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064846966 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.232        |\n",
      "|    explained_variance   | 0.765         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 377           |\n",
      "|    n_updates            | 4080          |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    value_loss           | 760           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 957         |\n",
      "|    total_timesteps      | 52480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005535594 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 378         |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    value_loss           | 775         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=52500, episode_reward=90.70 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 90.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 52500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038664127 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.263       |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 375          |\n",
      "|    n_updates            | 4100         |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    value_loss           | 755          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 411   |\n",
      "|    time_elapsed    | 959   |\n",
      "|    total_timesteps | 52608 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 412          |\n",
      "|    time_elapsed         | 961          |\n",
      "|    total_timesteps      | 52736        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127920685 |\n",
      "|    clip_fraction        | 0.0641       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.248       |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 288          |\n",
      "|    n_updates            | 4110         |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    value_loss           | 585          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 963         |\n",
      "|    total_timesteps      | 52864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009409874 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.189      |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 345         |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    value_loss           | 711         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 414          |\n",
      "|    time_elapsed         | 965          |\n",
      "|    total_timesteps      | 52992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020560913 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 268          |\n",
      "|    n_updates            | 4130         |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    value_loss           | 551          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=53000, episode_reward=71.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 71.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 53000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017753148 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.2         |\n",
      "|    explained_variance   | 0.854        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 189          |\n",
      "|    n_updates            | 4140         |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 382          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 415   |\n",
      "|    time_elapsed    | 967   |\n",
      "|    total_timesteps | 53120 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 416          |\n",
      "|    time_elapsed         | 970          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025657185 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.209       |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 4150         |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 253          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 972          |\n",
      "|    total_timesteps      | 53376        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023371095 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.193       |\n",
      "|    explained_variance   | 0.841        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 175          |\n",
      "|    n_updates            | 4160         |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    value_loss           | 360          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=53500, episode_reward=68.50 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 68.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 53500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017174764 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.148       |\n",
      "|    explained_variance   | 0.808        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 332          |\n",
      "|    n_updates            | 4170         |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    value_loss           | 676          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 418   |\n",
      "|    time_elapsed    | 975   |\n",
      "|    total_timesteps | 53504 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 419          |\n",
      "|    time_elapsed         | 977          |\n",
      "|    total_timesteps      | 53632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005148079 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.158       |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 351          |\n",
      "|    n_updates            | 4180         |\n",
      "|    policy_gradient_loss | -0.000796    |\n",
      "|    value_loss           | 714          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 420        |\n",
      "|    time_elapsed         | 980        |\n",
      "|    total_timesteps      | 53760      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00560644 |\n",
      "|    clip_fraction        | 0.0367     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.166     |\n",
      "|    explained_variance   | 0.794      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 295        |\n",
      "|    n_updates            | 4190       |\n",
      "|    policy_gradient_loss | -0.00506   |\n",
      "|    value_loss           | 599        |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 421           |\n",
      "|    time_elapsed         | 982           |\n",
      "|    total_timesteps      | 53888         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050527113 |\n",
      "|    clip_fraction        | 0.00234       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.163        |\n",
      "|    explained_variance   | 0.827         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 353           |\n",
      "|    n_updates            | 4200          |\n",
      "|    policy_gradient_loss | -0.000947     |\n",
      "|    value_loss           | 708           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=54000, episode_reward=20.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 20.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 54000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005687972 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.161      |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 358         |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    value_loss           | 722         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 422   |\n",
      "|    time_elapsed    | 984   |\n",
      "|    total_timesteps | 54016 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 986         |\n",
      "|    total_timesteps      | 54144       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002547531 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.126      |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 365         |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    value_loss           | 739         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 424          |\n",
      "|    time_elapsed         | 988          |\n",
      "|    total_timesteps      | 54272        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056498693 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.146       |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 242          |\n",
      "|    n_updates            | 4230         |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    value_loss           | 492          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 991         |\n",
      "|    total_timesteps      | 54400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010882808 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.149      |\n",
      "|    explained_variance   | 0.842       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    value_loss           | 355         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=54500, episode_reward=69.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 69.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 54500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004065221 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.171      |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    value_loss           | 236         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 426   |\n",
      "|    time_elapsed    | 994   |\n",
      "|    total_timesteps | 54528 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 427          |\n",
      "|    time_elapsed         | 996          |\n",
      "|    total_timesteps      | 54656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044300496 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.182       |\n",
      "|    explained_variance   | 0.872        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 201          |\n",
      "|    n_updates            | 4260         |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    value_loss           | 410          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 428          |\n",
      "|    time_elapsed         | 998          |\n",
      "|    total_timesteps      | 54784        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035435527 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.14        |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 339          |\n",
      "|    n_updates            | 4270         |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 681          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 429          |\n",
      "|    time_elapsed         | 1001         |\n",
      "|    total_timesteps      | 54912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024537107 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.151       |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 365          |\n",
      "|    n_updates            | 4280         |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    value_loss           | 735          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=61.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 61.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 55000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030501995 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.158       |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 368          |\n",
      "|    n_updates            | 4290         |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    value_loss           | 740          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 430   |\n",
      "|    time_elapsed    | 1003  |\n",
      "|    total_timesteps | 55040 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 431          |\n",
      "|    time_elapsed         | 1006         |\n",
      "|    total_timesteps      | 55168        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069952263 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.148       |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 437          |\n",
      "|    n_updates            | 4300         |\n",
      "|    policy_gradient_loss | -0.00784     |\n",
      "|    value_loss           | 882          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 432          |\n",
      "|    time_elapsed         | 1008         |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030793976 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 373          |\n",
      "|    n_updates            | 4310         |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 750          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 433          |\n",
      "|    time_elapsed         | 1010         |\n",
      "|    total_timesteps      | 55424        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020977035 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.11        |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 318          |\n",
      "|    n_updates            | 4320         |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    value_loss           | 640          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=55500, episode_reward=7.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 7.1          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 55500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053141457 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.116       |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 233          |\n",
      "|    n_updates            | 4330         |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 469          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 434   |\n",
      "|    time_elapsed    | 1012  |\n",
      "|    total_timesteps | 55552 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 435          |\n",
      "|    time_elapsed         | 1014         |\n",
      "|    total_timesteps      | 55680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029035548 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.128       |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 248          |\n",
      "|    n_updates            | 4340         |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    value_loss           | 506          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 436          |\n",
      "|    time_elapsed         | 1017         |\n",
      "|    total_timesteps      | 55808        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061285845 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.133       |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 123          |\n",
      "|    n_updates            | 4350         |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    value_loss           | 278          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 1020        |\n",
      "|    total_timesteps      | 55936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007677667 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.144      |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=56000, episode_reward=73.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 73.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 56000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012641823 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.137      |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 320         |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    value_loss           | 642         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 438   |\n",
      "|    time_elapsed    | 1022  |\n",
      "|    total_timesteps | 56064 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 1025        |\n",
      "|    total_timesteps      | 56192       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018976254 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.174      |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 359         |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    value_loss           | 725         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 1027        |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007828627 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.193      |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 343         |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    value_loss           | 693         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 1029        |\n",
      "|    total_timesteps      | 56448       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005812907 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.192      |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 376         |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    value_loss           | 758         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=56500, episode_reward=92.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 92.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 56500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009926777 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.196      |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 335         |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    value_loss           | 675         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 442   |\n",
      "|    time_elapsed    | 1031  |\n",
      "|    total_timesteps | 56576 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 443          |\n",
      "|    time_elapsed         | 1033         |\n",
      "|    total_timesteps      | 56704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051772846 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.204       |\n",
      "|    explained_variance   | 0.857        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 362          |\n",
      "|    n_updates            | 4420         |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    value_loss           | 733          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 444          |\n",
      "|    time_elapsed         | 1035         |\n",
      "|    total_timesteps      | 56832        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044332435 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 239          |\n",
      "|    n_updates            | 4430         |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    value_loss           | 485          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 445          |\n",
      "|    time_elapsed         | 1037         |\n",
      "|    total_timesteps      | 56960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051203724 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.203       |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 245          |\n",
      "|    n_updates            | 4440         |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    value_loss           | 505          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=57000, episode_reward=67.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 67.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 57000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011659088 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.196      |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    value_loss           | 287         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 446   |\n",
      "|    time_elapsed    | 1040  |\n",
      "|    total_timesteps | 57088 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 1042        |\n",
      "|    total_timesteps      | 57216       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003998158 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.182      |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 1045        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002762114 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.144      |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 315         |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    value_loss           | 637         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 449           |\n",
      "|    time_elapsed         | 1047          |\n",
      "|    total_timesteps      | 57472         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080825924 |\n",
      "|    clip_fraction        | 0.00547       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.139        |\n",
      "|    explained_variance   | 0.819         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 337           |\n",
      "|    n_updates            | 4480          |\n",
      "|    policy_gradient_loss | -0.000126     |\n",
      "|    value_loss           | 679           |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=57500, episode_reward=65.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 65          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 57500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003102738 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.151      |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 336         |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    value_loss           | 686         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 450   |\n",
      "|    time_elapsed    | 1050  |\n",
      "|    total_timesteps | 57600 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 1052        |\n",
      "|    total_timesteps      | 57728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011481128 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.164      |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 319         |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    value_loss           | 650         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 1054        |\n",
      "|    total_timesteps      | 57856       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004826516 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.183      |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 338         |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    value_loss           | 679         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 1056        |\n",
      "|    total_timesteps      | 57984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001811787 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.17       |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 316         |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    value_loss           | 637         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=58000, episode_reward=68.50 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 88         |\n",
      "|    mean_reward          | 68.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 58000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00069088 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.161     |\n",
      "|    explained_variance   | 0.868      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 221        |\n",
      "|    n_updates            | 4530       |\n",
      "|    policy_gradient_loss | -0.000549  |\n",
      "|    value_loss           | 451        |\n",
      "----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 454   |\n",
      "|    time_elapsed    | 1058  |\n",
      "|    total_timesteps | 58112 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 455         |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 58240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011262928 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.204      |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 225         |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    value_loss           | 458         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 456          |\n",
      "|    time_elapsed         | 1063         |\n",
      "|    total_timesteps      | 58368        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135389995 |\n",
      "|    clip_fraction        | 0.0977       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.241       |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 149          |\n",
      "|    n_updates            | 4550         |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 302          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 1066        |\n",
      "|    total_timesteps      | 58496       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005106642 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    value_loss           | 314         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=58500, episode_reward=81.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 81.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 58500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022438623 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.224       |\n",
      "|    explained_variance   | 0.808        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 289          |\n",
      "|    n_updates            | 4570         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 589          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 458   |\n",
      "|    time_elapsed    | 1068  |\n",
      "|    total_timesteps | 58624 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 459          |\n",
      "|    time_elapsed         | 1071         |\n",
      "|    total_timesteps      | 58752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035374812 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.19        |\n",
      "|    explained_variance   | 0.838        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 277          |\n",
      "|    n_updates            | 4580         |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 560          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 460          |\n",
      "|    time_elapsed         | 1073         |\n",
      "|    total_timesteps      | 58880        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019312073 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.201       |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 334          |\n",
      "|    n_updates            | 4590         |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    value_loss           | 673          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=59000, episode_reward=83.75 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 83.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 59000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004627863 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 362         |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    value_loss           | 730         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 461   |\n",
      "|    time_elapsed    | 1076  |\n",
      "|    total_timesteps | 59008 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 462          |\n",
      "|    time_elapsed         | 1078         |\n",
      "|    total_timesteps      | 59136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018523224 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.248       |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 347          |\n",
      "|    n_updates            | 4610         |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 701          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 463          |\n",
      "|    time_elapsed         | 1080         |\n",
      "|    total_timesteps      | 59264        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017270264 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.246       |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 346          |\n",
      "|    n_updates            | 4620         |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    value_loss           | 697          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 1082        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004042324 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.228      |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 347         |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    value_loss           | 705         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=59500, episode_reward=96.25 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 96.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 59500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059917206 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.264       |\n",
      "|    explained_variance   | 0.841        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 212          |\n",
      "|    n_updates            | 4640         |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    value_loss           | 435          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 465   |\n",
      "|    time_elapsed    | 1084  |\n",
      "|    total_timesteps | 59520 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 466          |\n",
      "|    time_elapsed         | 1087         |\n",
      "|    total_timesteps      | 59648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050059883 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.258       |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 187          |\n",
      "|    n_updates            | 4650         |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 425          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 1090        |\n",
      "|    total_timesteps      | 59776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011159942 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 468          |\n",
      "|    time_elapsed         | 1092         |\n",
      "|    total_timesteps      | 59904        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048053963 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.241       |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 241          |\n",
      "|    n_updates            | 4670         |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    value_loss           | 492          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=83.75 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 83.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001988065 |\n",
      "|    clip_fraction        | 0.0102      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.207      |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 330         |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    value_loss           | 666         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 469   |\n",
      "|    time_elapsed    | 1095  |\n",
      "|    total_timesteps | 60032 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 1098         |\n",
      "|    total_timesteps      | 60160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035348402 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.209       |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 394          |\n",
      "|    n_updates            | 4690         |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    value_loss           | 826          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 1100        |\n",
      "|    total_timesteps      | 60288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002711232 |\n",
      "|    clip_fraction        | 0.00234     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 327         |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    value_loss           | 660         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 1102        |\n",
      "|    total_timesteps      | 60416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004237984 |\n",
      "|    clip_fraction        | 0.00625     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 316         |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    value_loss           | 635         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60500, episode_reward=89.95 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 89.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015228501 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 351         |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    value_loss           | 706         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 473   |\n",
      "|    time_elapsed    | 1104  |\n",
      "|    total_timesteps | 60544 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 474         |\n",
      "|    time_elapsed         | 1106        |\n",
      "|    total_timesteps      | 60672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007360624 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.233      |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 328         |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 660         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 475        |\n",
      "|    time_elapsed         | 1108       |\n",
      "|    total_timesteps      | 60800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00602867 |\n",
      "|    clip_fraction        | 0.0109     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.278     |\n",
      "|    explained_variance   | 0.885      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 183        |\n",
      "|    n_updates            | 4740       |\n",
      "|    policy_gradient_loss | -0.00698   |\n",
      "|    value_loss           | 372        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 1111        |\n",
      "|    total_timesteps      | 60928       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047937065 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 371         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=61000, episode_reward=91.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 91.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 61000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008000483 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 185         |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 477   |\n",
      "|    time_elapsed    | 1114  |\n",
      "|    total_timesteps | 61056 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 1116        |\n",
      "|    total_timesteps      | 61184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004964533 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    value_loss           | 376         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 479          |\n",
      "|    time_elapsed         | 1118         |\n",
      "|    total_timesteps      | 61312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028033385 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.221       |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 312          |\n",
      "|    n_updates            | 4780         |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    value_loss           | 629          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 480          |\n",
      "|    time_elapsed         | 1121         |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029075705 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.215       |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 319          |\n",
      "|    n_updates            | 4790         |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    value_loss           | 642          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=61500, episode_reward=95.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 95.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 61500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058387658 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.241       |\n",
      "|    explained_variance   | 0.867        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 325          |\n",
      "|    n_updates            | 4800         |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    value_loss           | 654          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 481   |\n",
      "|    time_elapsed    | 1123  |\n",
      "|    total_timesteps | 61568 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 1125        |\n",
      "|    total_timesteps      | 61696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004046991 |\n",
      "|    clip_fraction        | 0.00781     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 325         |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 655         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 483          |\n",
      "|    time_elapsed         | 1127         |\n",
      "|    total_timesteps      | 61824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070201876 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.243       |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 273          |\n",
      "|    n_updates            | 4820         |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 555          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 484          |\n",
      "|    time_elapsed         | 1129         |\n",
      "|    total_timesteps      | 61952        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024204329 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.207       |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 325          |\n",
      "|    n_updates            | 4830         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 656          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=62000, episode_reward=84.45 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 84.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 62000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002191653 |\n",
      "|    clip_fraction        | 0.00703     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.231      |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 262         |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    value_loss           | 542         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 485   |\n",
      "|    time_elapsed    | 1132  |\n",
      "|    total_timesteps | 62080 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 1134        |\n",
      "|    total_timesteps      | 62208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008640416 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    value_loss           | 333         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 1137        |\n",
      "|    total_timesteps      | 62336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005826888 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.4        |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 1139        |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023071513 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.8        |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=62500, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 95.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 62500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005065744 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.223      |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 284         |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    value_loss           | 575         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 489   |\n",
      "|    time_elapsed    | 1142  |\n",
      "|    total_timesteps | 62592 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 1145        |\n",
      "|    total_timesteps      | 62720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025993532 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.206      |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 340         |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 687         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 491          |\n",
      "|    time_elapsed         | 1147         |\n",
      "|    total_timesteps      | 62848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022519468 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.229       |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 281          |\n",
      "|    n_updates            | 4900         |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 572          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 1149        |\n",
      "|    total_timesteps      | 62976       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012904357 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 281         |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    value_loss           | 567         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=63000, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 95.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 63000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005987267 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 290         |\n",
      "|    n_updates            | 4920        |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    value_loss           | 591         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 493   |\n",
      "|    time_elapsed    | 1152  |\n",
      "|    total_timesteps | 63104 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 494          |\n",
      "|    time_elapsed         | 1154         |\n",
      "|    total_timesteps      | 63232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041709794 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.226       |\n",
      "|    explained_variance   | 0.865        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 299          |\n",
      "|    n_updates            | 4930         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 607          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 1156        |\n",
      "|    total_timesteps      | 63360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013042419 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 214         |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    value_loss           | 444         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 1158        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007377564 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    value_loss           | 293         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=63500, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 92           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 63500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140948165 |\n",
      "|    clip_fraction        | 0.0555       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.267       |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 4960         |\n",
      "|    policy_gradient_loss | -0.0095      |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 497   |\n",
      "|    time_elapsed    | 1161  |\n",
      "|    total_timesteps | 63616 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 498          |\n",
      "|    time_elapsed         | 1162         |\n",
      "|    total_timesteps      | 63744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013044339 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.263       |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 4970         |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    value_loss           | 230          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 1165        |\n",
      "|    total_timesteps      | 63872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003394945 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.207      |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 280         |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    value_loss           | 580         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=87.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 87.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 64000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064271856 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.185       |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 297          |\n",
      "|    n_updates            | 4990         |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    value_loss           | 603          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 500   |\n",
      "|    time_elapsed    | 1168  |\n",
      "|    total_timesteps | 64000 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 501          |\n",
      "|    time_elapsed         | 1171         |\n",
      "|    total_timesteps      | 64128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014465067 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.188       |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 304          |\n",
      "|    n_updates            | 5000         |\n",
      "|    policy_gradient_loss | -0.000857    |\n",
      "|    value_loss           | 611          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 502        |\n",
      "|    time_elapsed         | 1173       |\n",
      "|    total_timesteps      | 64256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03470237 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.245     |\n",
      "|    explained_variance   | 0.861      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 332        |\n",
      "|    n_updates            | 5010       |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    value_loss           | 670        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 503          |\n",
      "|    time_elapsed         | 1175         |\n",
      "|    total_timesteps      | 64384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034763075 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.248       |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 354          |\n",
      "|    n_updates            | 5020         |\n",
      "|    policy_gradient_loss | -0.00759     |\n",
      "|    value_loss           | 726          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=64500, episode_reward=86.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 86.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002663745 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.204      |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 325         |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | -0.000566   |\n",
      "|    value_loss           | 654         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 504   |\n",
      "|    time_elapsed    | 1177  |\n",
      "|    total_timesteps | 64512 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 505          |\n",
      "|    time_elapsed         | 1179         |\n",
      "|    total_timesteps      | 64640        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055332654 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.231       |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 224          |\n",
      "|    n_updates            | 5040         |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    value_loss           | 457          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 506        |\n",
      "|    time_elapsed         | 1182       |\n",
      "|    total_timesteps      | 64768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03397827 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.252     |\n",
      "|    explained_variance   | 0.874      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 236        |\n",
      "|    n_updates            | 5050       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 480        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 507          |\n",
      "|    time_elapsed         | 1185         |\n",
      "|    total_timesteps      | 64896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031089347 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.249       |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 5060         |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=87.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 87.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 65000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074422257 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.246       |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 123          |\n",
      "|    n_updates            | 5070         |\n",
      "|    policy_gradient_loss | -0.00676     |\n",
      "|    value_loss           | 249          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 508   |\n",
      "|    time_elapsed    | 1187  |\n",
      "|    total_timesteps | 65024 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 509          |\n",
      "|    time_elapsed         | 1189         |\n",
      "|    total_timesteps      | 65152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026134953 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.203       |\n",
      "|    explained_variance   | 0.883        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 301          |\n",
      "|    n_updates            | 5080         |\n",
      "|    policy_gradient_loss | -0.000845    |\n",
      "|    value_loss           | 606          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 510        |\n",
      "|    time_elapsed         | 1192       |\n",
      "|    total_timesteps      | 65280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00255536 |\n",
      "|    clip_fraction        | 0.0109     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.175     |\n",
      "|    explained_variance   | 0.858      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 308        |\n",
      "|    n_updates            | 5090       |\n",
      "|    policy_gradient_loss | -0.00353   |\n",
      "|    value_loss           | 619        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 511          |\n",
      "|    time_elapsed         | 1194         |\n",
      "|    total_timesteps      | 65408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027862152 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.195       |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 334          |\n",
      "|    n_updates            | 5100         |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    value_loss           | 675          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=65500, episode_reward=86.20 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 88       |\n",
      "|    mean_reward          | 86.2     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 65500    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.009722 |\n",
      "|    clip_fraction        | 0.0844   |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.228   |\n",
      "|    explained_variance   | 0.879    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 317      |\n",
      "|    n_updates            | 5110     |\n",
      "|    policy_gradient_loss | -0.0063  |\n",
      "|    value_loss           | 637      |\n",
      "--------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 512   |\n",
      "|    time_elapsed    | 1197  |\n",
      "|    total_timesteps | 65536 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 513        |\n",
      "|    time_elapsed         | 1199       |\n",
      "|    total_timesteps      | 65664      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00675671 |\n",
      "|    clip_fraction        | 0.0461     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.225     |\n",
      "|    explained_variance   | 0.852      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 311        |\n",
      "|    n_updates            | 5120       |\n",
      "|    policy_gradient_loss | -0.00462   |\n",
      "|    value_loss           | 632        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 514          |\n",
      "|    time_elapsed         | 1201         |\n",
      "|    total_timesteps      | 65792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025327476 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.221       |\n",
      "|    explained_variance   | 0.872        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 291          |\n",
      "|    n_updates            | 5130         |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    value_loss           | 590          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 515          |\n",
      "|    time_elapsed         | 1203         |\n",
      "|    total_timesteps      | 65920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064903744 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 224          |\n",
      "|    n_updates            | 5140         |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    value_loss           | 452          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=66000, episode_reward=91.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 91.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 66000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012861984 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 497         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 516   |\n",
      "|    time_elapsed    | 1205  |\n",
      "|    total_timesteps | 66048 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 517          |\n",
      "|    time_elapsed         | 1208         |\n",
      "|    total_timesteps      | 66176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021247738 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.246       |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 5160         |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    value_loss           | 296          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 518          |\n",
      "|    time_elapsed         | 1210         |\n",
      "|    total_timesteps      | 66304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034700565 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.246       |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 90.5         |\n",
      "|    n_updates            | 5170         |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 519          |\n",
      "|    time_elapsed         | 1213         |\n",
      "|    total_timesteps      | 66432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027069321 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.2         |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 268          |\n",
      "|    n_updates            | 5180         |\n",
      "|    policy_gradient_loss | -0.000954    |\n",
      "|    value_loss           | 543          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=66500, episode_reward=91.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 91.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 66500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077912654 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 307          |\n",
      "|    n_updates            | 5190         |\n",
      "|    policy_gradient_loss | -0.00766     |\n",
      "|    value_loss           | 618          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 520   |\n",
      "|    time_elapsed    | 1215  |\n",
      "|    total_timesteps | 66560 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 521          |\n",
      "|    time_elapsed         | 1218         |\n",
      "|    total_timesteps      | 66688        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049144165 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.847        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 300          |\n",
      "|    n_updates            | 5200         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 604          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 522          |\n",
      "|    time_elapsed         | 1220         |\n",
      "|    total_timesteps      | 66816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018480632 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.222       |\n",
      "|    explained_variance   | 0.872        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 293          |\n",
      "|    n_updates            | 5210         |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    value_loss           | 594          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 1222        |\n",
      "|    total_timesteps      | 66944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007588671 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    value_loss           | 468         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=67000, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 92          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 67000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005744655 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.214      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 272         |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    value_loss           | 553         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 524   |\n",
      "|    time_elapsed    | 1224  |\n",
      "|    total_timesteps | 67072 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 525          |\n",
      "|    time_elapsed         | 1226         |\n",
      "|    total_timesteps      | 67200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034372064 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.198       |\n",
      "|    explained_variance   | 0.889        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 5240         |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    value_loss           | 422          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 1228        |\n",
      "|    total_timesteps      | 67328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004773931 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.222      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 422         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 1231        |\n",
      "|    total_timesteps      | 67456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020260008 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.223      |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=67500, episode_reward=50.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 50.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 67500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010273136 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.234      |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    value_loss           | 236         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 528   |\n",
      "|    time_elapsed    | 1234  |\n",
      "|    total_timesteps | 67584 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 1236        |\n",
      "|    total_timesteps      | 67712       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009084158 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.198      |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 260         |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    value_loss           | 527         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 1238        |\n",
      "|    total_timesteps      | 67840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005158999 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.187      |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 293         |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    value_loss           | 594         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 531          |\n",
      "|    time_elapsed         | 1240         |\n",
      "|    total_timesteps      | 67968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056151412 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.17        |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 297          |\n",
      "|    n_updates            | 5300         |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 606          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=68000, episode_reward=38.70 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 38.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 68000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032038754 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.863        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 350          |\n",
      "|    n_updates            | 5310         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 703          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 532   |\n",
      "|    time_elapsed    | 1243  |\n",
      "|    total_timesteps | 68096 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 533         |\n",
      "|    time_elapsed         | 1245        |\n",
      "|    total_timesteps      | 68224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002286795 |\n",
      "|    clip_fraction        | 0.00859     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.207      |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 308         |\n",
      "|    n_updates            | 5320        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    value_loss           | 620         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 534          |\n",
      "|    time_elapsed         | 1247         |\n",
      "|    total_timesteps      | 68352        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021795575 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 317          |\n",
      "|    n_updates            | 5330         |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 640          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 535          |\n",
      "|    time_elapsed         | 1249         |\n",
      "|    total_timesteps      | 68480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022277012 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 303          |\n",
      "|    n_updates            | 5340         |\n",
      "|    policy_gradient_loss | -0.000985    |\n",
      "|    value_loss           | 612          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=68500, episode_reward=43.15 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 43.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 68500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026924056 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.866        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 202          |\n",
      "|    n_updates            | 5350         |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 414          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 536   |\n",
      "|    time_elapsed    | 1252  |\n",
      "|    total_timesteps | 68608 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 1255        |\n",
      "|    total_timesteps      | 68736       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003993312 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.184      |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 538         |\n",
      "|    time_elapsed         | 1257        |\n",
      "|    total_timesteps      | 68864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003333905 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.188      |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 83.2        |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 539          |\n",
      "|    time_elapsed         | 1260         |\n",
      "|    total_timesteps      | 68992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011757659 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.171       |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 223          |\n",
      "|    n_updates            | 5380         |\n",
      "|    policy_gradient_loss | -0.000268    |\n",
      "|    value_loss           | 448          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=69000, episode_reward=28.40 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 28.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 69000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014220837 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.148       |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 281          |\n",
      "|    n_updates            | 5390         |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    value_loss           | 566          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 540   |\n",
      "|    time_elapsed    | 1262  |\n",
      "|    total_timesteps | 69120 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 541          |\n",
      "|    time_elapsed         | 1265         |\n",
      "|    total_timesteps      | 69248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024257614 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.145       |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 286          |\n",
      "|    n_updates            | 5400         |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 579          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 542          |\n",
      "|    time_elapsed         | 1267         |\n",
      "|    total_timesteps      | 69376        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031825872 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.148       |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 241          |\n",
      "|    n_updates            | 5410         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 486          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=69500, episode_reward=17.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 17.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 69500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000384151 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.155      |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 292         |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.00107    |\n",
      "|    value_loss           | 587         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 543   |\n",
      "|    time_elapsed    | 1270  |\n",
      "|    total_timesteps | 69504 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 544          |\n",
      "|    time_elapsed         | 1272         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021092019 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.151       |\n",
      "|    explained_variance   | 0.899        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 265          |\n",
      "|    n_updates            | 5430         |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    value_loss           | 534          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 545          |\n",
      "|    time_elapsed         | 1274         |\n",
      "|    total_timesteps      | 69760        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026993258 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.116       |\n",
      "|    explained_variance   | 0.885        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 284          |\n",
      "|    n_updates            | 5440         |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 573          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 1276        |\n",
      "|    total_timesteps      | 69888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017175868 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.154      |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    value_loss           | 371         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=32.25 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 32.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064328173 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.173       |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 5460         |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 295          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 547   |\n",
      "|    time_elapsed    | 1279  |\n",
      "|    total_timesteps | 70016 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 548        |\n",
      "|    time_elapsed         | 1282       |\n",
      "|    total_timesteps      | 70144      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01712194 |\n",
      "|    clip_fraction        | 0.0773     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.165     |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 105        |\n",
      "|    n_updates            | 5470       |\n",
      "|    policy_gradient_loss | -0.00674   |\n",
      "|    value_loss           | 216        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 1284        |\n",
      "|    total_timesteps      | 70272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006821596 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.16       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 550          |\n",
      "|    time_elapsed         | 1286         |\n",
      "|    total_timesteps      | 70400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019410304 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.144       |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 290          |\n",
      "|    n_updates            | 5490         |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    value_loss           | 597          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70500, episode_reward=21.50 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 88            |\n",
      "|    mean_reward          | 21.5          |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 70500         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039772806 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.154        |\n",
      "|    explained_variance   | 0.899         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 286           |\n",
      "|    n_updates            | 5500          |\n",
      "|    policy_gradient_loss | -0.00144      |\n",
      "|    value_loss           | 577           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 551   |\n",
      "|    time_elapsed    | 1289  |\n",
      "|    total_timesteps | 70528 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 552          |\n",
      "|    time_elapsed         | 1292         |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028622514 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.157       |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 252          |\n",
      "|    n_updates            | 5510         |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    value_loss           | 515          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 1293        |\n",
      "|    total_timesteps      | 70784       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002089097 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.173      |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 259         |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    value_loss           | 523         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 1295        |\n",
      "|    total_timesteps      | 70912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019100603 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.177      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 282         |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    value_loss           | 577         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=71000, episode_reward=54.55 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 54.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 71000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002847602 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.165      |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 253         |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    value_loss           | 510         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 555   |\n",
      "|    time_elapsed    | 1297  |\n",
      "|    total_timesteps | 71040 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 556          |\n",
      "|    time_elapsed         | 1300         |\n",
      "|    total_timesteps      | 71168        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012386474 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 218          |\n",
      "|    n_updates            | 5550         |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    value_loss           | 443          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 557          |\n",
      "|    time_elapsed         | 1302         |\n",
      "|    total_timesteps      | 71296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058373488 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.19        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 5560         |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    value_loss           | 314          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 1304        |\n",
      "|    total_timesteps      | 71424       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003455865 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.191      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=71500, episode_reward=28.40 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 28.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 71500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031998702 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.187       |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 158          |\n",
      "|    n_updates            | 5580         |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    value_loss           | 324          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 559   |\n",
      "|    time_elapsed    | 1307  |\n",
      "|    total_timesteps | 71552 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 560          |\n",
      "|    time_elapsed         | 1309         |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024646693 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.151       |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 274          |\n",
      "|    n_updates            | 5590         |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    value_loss           | 552          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 561          |\n",
      "|    time_elapsed         | 1312         |\n",
      "|    total_timesteps      | 71808        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016033067 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.154       |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 275          |\n",
      "|    n_updates            | 5600         |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    value_loss           | 554          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 562          |\n",
      "|    time_elapsed         | 1314         |\n",
      "|    total_timesteps      | 71936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018538502 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.165       |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 259          |\n",
      "|    n_updates            | 5610         |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 521          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=64.45 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 64.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 72000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017312216 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.188       |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 243          |\n",
      "|    n_updates            | 5620         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 492          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 563   |\n",
      "|    time_elapsed    | 1316  |\n",
      "|    total_timesteps | 72064 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 564          |\n",
      "|    time_elapsed         | 1318         |\n",
      "|    total_timesteps      | 72192        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015677835 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.217       |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 215          |\n",
      "|    n_updates            | 5630         |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    value_loss           | 433          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 565          |\n",
      "|    time_elapsed         | 1320         |\n",
      "|    total_timesteps      | 72320        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068377373 |\n",
      "|    clip_fraction        | 0.0578       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.164       |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 292          |\n",
      "|    n_updates            | 5640         |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    value_loss           | 588          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 566          |\n",
      "|    time_elapsed         | 1322         |\n",
      "|    total_timesteps      | 72448        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065206946 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.189       |\n",
      "|    explained_variance   | 0.906        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 207          |\n",
      "|    n_updates            | 5650         |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    value_loss           | 420          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=72500, episode_reward=32.25 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 32.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 72500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025987055 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.177       |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 140          |\n",
      "|    n_updates            | 5660         |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    value_loss           | 285          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 567   |\n",
      "|    time_elapsed    | 1325  |\n",
      "|    total_timesteps | 72576 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 1328        |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014015749 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.205      |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.1        |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 1330        |\n",
      "|    total_timesteps      | 72832       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005198558 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.231      |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 1333        |\n",
      "|    total_timesteps      | 72960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009891903 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.2        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 236         |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    value_loss           | 479         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=73000, episode_reward=95.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 95.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 73000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009571513 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.203      |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 273         |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    value_loss           | 554         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 571   |\n",
      "|    time_elapsed    | 1335  |\n",
      "|    total_timesteps | 73088 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 572         |\n",
      "|    time_elapsed         | 1337        |\n",
      "|    total_timesteps      | 73216       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008675552 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.221      |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 289         |\n",
      "|    n_updates            | 5710        |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    value_loss           | 585         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 1339        |\n",
      "|    total_timesteps      | 73344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009939656 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 289         |\n",
      "|    n_updates            | 5720        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    value_loss           | 585         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 1341        |\n",
      "|    total_timesteps      | 73472       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019350102 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 272         |\n",
      "|    n_updates            | 5730        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    value_loss           | 558         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=73500, episode_reward=86.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 86.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 73500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029927797 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.236       |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 254          |\n",
      "|    n_updates            | 5740         |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 515          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 575   |\n",
      "|    time_elapsed    | 1343  |\n",
      "|    total_timesteps | 73600 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 576          |\n",
      "|    time_elapsed         | 1346         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036483004 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.257       |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 238          |\n",
      "|    n_updates            | 5750         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 484          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 1348        |\n",
      "|    total_timesteps      | 73856       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009398115 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 208         |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    value_loss           | 421         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 578          |\n",
      "|    time_elapsed         | 1351         |\n",
      "|    total_timesteps      | 73984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060277693 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.261       |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 97.4         |\n",
      "|    n_updates            | 5770         |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 217          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=74000, episode_reward=87.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 88         |\n",
      "|    mean_reward          | 87.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 74000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01007679 |\n",
      "|    clip_fraction        | 0.0289     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.265     |\n",
      "|    explained_variance   | 0.93       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 115        |\n",
      "|    n_updates            | 5780       |\n",
      "|    policy_gradient_loss | -0.00554   |\n",
      "|    value_loss           | 235        |\n",
      "----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 579   |\n",
      "|    time_elapsed    | 1353  |\n",
      "|    total_timesteps | 74112 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 1355        |\n",
      "|    total_timesteps      | 74240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003640509 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.212      |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 243         |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    value_loss           | 489         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 1358        |\n",
      "|    total_timesteps      | 74368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014009709 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.183      |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    value_loss           | 426         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 582          |\n",
      "|    time_elapsed         | 1360         |\n",
      "|    total_timesteps      | 74496        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023628029 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.175       |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 265          |\n",
      "|    n_updates            | 5810         |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    value_loss           | 535          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=74500, episode_reward=87.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 87.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 74500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010520331 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.225      |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 265         |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    value_loss           | 538         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 583   |\n",
      "|    time_elapsed    | 1362  |\n",
      "|    total_timesteps | 74624 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 584          |\n",
      "|    time_elapsed         | 1364         |\n",
      "|    total_timesteps      | 74752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010273848 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.248       |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 256          |\n",
      "|    n_updates            | 5830         |\n",
      "|    policy_gradient_loss | -0.000177    |\n",
      "|    value_loss           | 518          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 585          |\n",
      "|    time_elapsed         | 1366         |\n",
      "|    total_timesteps      | 74880        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004326154 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.234       |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 263          |\n",
      "|    n_updates            | 5840         |\n",
      "|    policy_gradient_loss | -0.000571    |\n",
      "|    value_loss           | 530          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=83.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 83           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 75000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023678313 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.239       |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 195          |\n",
      "|    n_updates            | 5850         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 397          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 586   |\n",
      "|    time_elapsed    | 1369  |\n",
      "|    total_timesteps | 75008 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 587          |\n",
      "|    time_elapsed         | 1371         |\n",
      "|    total_timesteps      | 75136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076471646 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.261       |\n",
      "|    explained_variance   | 0.916        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 198          |\n",
      "|    n_updates            | 5860         |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    value_loss           | 407          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 1373        |\n",
      "|    total_timesteps      | 75264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005775339 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 589        |\n",
      "|    time_elapsed         | 1376       |\n",
      "|    total_timesteps      | 75392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01639633 |\n",
      "|    clip_fraction        | 0.0625     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.265     |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 81.4       |\n",
      "|    n_updates            | 5880       |\n",
      "|    policy_gradient_loss | -0.00879   |\n",
      "|    value_loss           | 172        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=75500, episode_reward=87.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 87.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 75500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007456946 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.223      |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    value_loss           | 424         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 590   |\n",
      "|    time_elapsed    | 1378  |\n",
      "|    total_timesteps | 75520 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 591          |\n",
      "|    time_elapsed         | 1381         |\n",
      "|    total_timesteps      | 75648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059660636 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.198       |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 214          |\n",
      "|    n_updates            | 5900         |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    value_loss           | 432          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 592           |\n",
      "|    time_elapsed         | 1383          |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020770845 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.188        |\n",
      "|    explained_variance   | 0.897         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 233           |\n",
      "|    n_updates            | 5910          |\n",
      "|    policy_gradient_loss | 0.000651      |\n",
      "|    value_loss           | 470           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 593          |\n",
      "|    time_elapsed         | 1386         |\n",
      "|    total_timesteps      | 75904        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068057664 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 0.902        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 210          |\n",
      "|    n_updates            | 5920         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 425          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=76000, episode_reward=91.95 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 91.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 76000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007464465 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    value_loss           | 469         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 594   |\n",
      "|    time_elapsed    | 1388  |\n",
      "|    total_timesteps | 76032 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 1390        |\n",
      "|    total_timesteps      | 76160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003310006 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.223      |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 207         |\n",
      "|    n_updates            | 5940        |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    value_loss           | 421         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 596         |\n",
      "|    time_elapsed         | 1392        |\n",
      "|    total_timesteps      | 76288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008149117 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.222      |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    value_loss           | 400         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 1394        |\n",
      "|    total_timesteps      | 76416       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004110478 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 386         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=76500, episode_reward=95.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 95.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 76500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059351297 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.258       |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 95           |\n",
      "|    n_updates            | 5970         |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 598   |\n",
      "|    time_elapsed    | 1397  |\n",
      "|    total_timesteps | 76544 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 599          |\n",
      "|    time_elapsed         | 1399         |\n",
      "|    total_timesteps      | 76672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032198743 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.263       |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 59.2         |\n",
      "|    n_updates            | 5980         |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 600          |\n",
      "|    time_elapsed         | 1402         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029755759 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.226       |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 189          |\n",
      "|    n_updates            | 5990         |\n",
      "|    policy_gradient_loss | -0.000919    |\n",
      "|    value_loss           | 409          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 601          |\n",
      "|    time_elapsed         | 1405         |\n",
      "|    total_timesteps      | 76928        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045506707 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.189       |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 218          |\n",
      "|    n_updates            | 6000         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 440          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=77000, episode_reward=91.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 91.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 77000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019383613 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.205      |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 6010        |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    value_loss           | 421         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 602   |\n",
      "|    time_elapsed    | 1407  |\n",
      "|    total_timesteps | 77056 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 1409        |\n",
      "|    total_timesteps      | 77184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006189433 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    value_loss           | 406         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 604       |\n",
      "|    time_elapsed         | 1411      |\n",
      "|    total_timesteps      | 77312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0326231 |\n",
      "|    clip_fraction        | 0.18      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.256    |\n",
      "|    explained_variance   | 0.908     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 230       |\n",
      "|    n_updates            | 6030      |\n",
      "|    policy_gradient_loss | -0.0106   |\n",
      "|    value_loss           | 467       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 605          |\n",
      "|    time_elapsed         | 1413         |\n",
      "|    total_timesteps      | 77440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031047664 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.247       |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 212          |\n",
      "|    n_updates            | 6040         |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    value_loss           | 440          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=77500, episode_reward=86.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 88         |\n",
      "|    mean_reward          | 86         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 77500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01657077 |\n",
      "|    clip_fraction        | 0.0703     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.223     |\n",
      "|    explained_variance   | 0.928      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 160        |\n",
      "|    n_updates            | 6050       |\n",
      "|    policy_gradient_loss | -0.00967   |\n",
      "|    value_loss           | 340        |\n",
      "----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 606   |\n",
      "|    time_elapsed    | 1415  |\n",
      "|    total_timesteps | 77568 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 1418        |\n",
      "|    total_timesteps      | 77696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007011934 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    value_loss           | 374         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 608        |\n",
      "|    time_elapsed         | 1420       |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02322608 |\n",
      "|    clip_fraction        | 0.0891     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.26      |\n",
      "|    explained_variance   | 0.921      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 103        |\n",
      "|    n_updates            | 6070       |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    value_loss           | 222        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 609          |\n",
      "|    time_elapsed         | 1423         |\n",
      "|    total_timesteps      | 77952        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063906927 |\n",
      "|    clip_fraction        | 0.0836       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.254       |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 49           |\n",
      "|    n_updates            | 6080         |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=78000, episode_reward=86.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 86          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 78000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010401467 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.221      |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 6090        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    value_loss           | 348         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 610   |\n",
      "|    time_elapsed    | 1425  |\n",
      "|    total_timesteps | 78080 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 611          |\n",
      "|    time_elapsed         | 1427         |\n",
      "|    total_timesteps      | 78208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023771618 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.173       |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 243          |\n",
      "|    n_updates            | 6100         |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    value_loss           | 497          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 1430        |\n",
      "|    total_timesteps      | 78336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003800769 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.185      |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 6110        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    value_loss           | 401         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 613          |\n",
      "|    time_elapsed         | 1432         |\n",
      "|    total_timesteps      | 78464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025746922 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.215       |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 251          |\n",
      "|    n_updates            | 6120         |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 507          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=78500, episode_reward=86.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 86.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 78500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014234977 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.244       |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 266          |\n",
      "|    n_updates            | 6130         |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    value_loss           | 536          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 614   |\n",
      "|    time_elapsed    | 1435  |\n",
      "|    total_timesteps | 78592 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 1437        |\n",
      "|    total_timesteps      | 78720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009019239 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 254         |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    value_loss           | 513         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 616          |\n",
      "|    time_elapsed         | 1439         |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007725302 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.224       |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 267          |\n",
      "|    n_updates            | 6150         |\n",
      "|    policy_gradient_loss | -0.000916    |\n",
      "|    value_loss           | 540          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 617          |\n",
      "|    time_elapsed         | 1441         |\n",
      "|    total_timesteps      | 78976        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031298874 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.253       |\n",
      "|    explained_variance   | 0.902        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 175          |\n",
      "|    n_updates            | 6160         |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 361          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=79000, episode_reward=87.30 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 87.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 79000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037363153 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.246       |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 147          |\n",
      "|    n_updates            | 6170         |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    value_loss           | 295          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 618   |\n",
      "|    time_elapsed    | 1443  |\n",
      "|    total_timesteps | 79104 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 619          |\n",
      "|    time_elapsed         | 1446         |\n",
      "|    total_timesteps      | 79232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036950842 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.249       |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 88.7         |\n",
      "|    n_updates            | 6180         |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 620          |\n",
      "|    time_elapsed         | 1448         |\n",
      "|    total_timesteps      | 79360        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024319508 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 6190         |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    value_loss           | 270          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 621         |\n",
      "|    time_elapsed         | 1451        |\n",
      "|    total_timesteps      | 79488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004590371 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.183      |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 233         |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    value_loss           | 470         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=79500, episode_reward=96.20 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 96.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 79500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011223411 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.18       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 439         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 622   |\n",
      "|    time_elapsed    | 1453  |\n",
      "|    total_timesteps | 79616 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 623          |\n",
      "|    time_elapsed         | 1456         |\n",
      "|    total_timesteps      | 79744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075418004 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.213       |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 234          |\n",
      "|    n_updates            | 6220         |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    value_loss           | 478          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 624          |\n",
      "|    time_elapsed         | 1458         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013484214 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.245       |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 227          |\n",
      "|    n_updates            | 6230         |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 459          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=91.95 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 91.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057321056 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.247       |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 286          |\n",
      "|    n_updates            | 6240         |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 596          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 625   |\n",
      "|    time_elapsed    | 1460  |\n",
      "|    total_timesteps | 80000 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 1462        |\n",
      "|    total_timesteps      | 80128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006786454 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.217      |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 244         |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 503         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 627          |\n",
      "|    time_elapsed         | 1464         |\n",
      "|    total_timesteps      | 80256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051378366 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.25        |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 6260         |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 421          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 628          |\n",
      "|    time_elapsed         | 1466         |\n",
      "|    total_timesteps      | 80384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035801253 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.247       |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 6270         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    value_loss           | 327          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80500, episode_reward=96.20 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 96.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010894018 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.25        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 77.9         |\n",
      "|    n_updates            | 6280         |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 629   |\n",
      "|    time_elapsed    | 1469  |\n",
      "|    total_timesteps | 80512 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 630         |\n",
      "|    time_elapsed         | 1471        |\n",
      "|    total_timesteps      | 80640       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010367017 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.4        |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 631          |\n",
      "|    time_elapsed         | 1474         |\n",
      "|    total_timesteps      | 80768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042178836 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.175       |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 210          |\n",
      "|    n_updates            | 6300         |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    value_loss           | 425          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 632          |\n",
      "|    time_elapsed         | 1476         |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020027459 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.171       |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 233          |\n",
      "|    n_updates            | 6310         |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 477          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=81000, episode_reward=92.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 92           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 81000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021971178 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.193       |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 234          |\n",
      "|    n_updates            | 6320         |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 479          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 633   |\n",
      "|    time_elapsed    | 1479  |\n",
      "|    total_timesteps | 81024 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 1481        |\n",
      "|    total_timesteps      | 81152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006329946 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.214      |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    value_loss           | 460         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 635          |\n",
      "|    time_elapsed         | 1483         |\n",
      "|    total_timesteps      | 81280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040496066 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.213       |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 193          |\n",
      "|    n_updates            | 6340         |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    value_loss           | 393          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 636          |\n",
      "|    time_elapsed         | 1485         |\n",
      "|    total_timesteps      | 81408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024503672 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.185       |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 195          |\n",
      "|    n_updates            | 6350         |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 400          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=81500, episode_reward=83.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 83          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 81500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004322129 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.2        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    value_loss           | 410         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 637   |\n",
      "|    time_elapsed    | 1487  |\n",
      "|    total_timesteps | 81536 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 1490        |\n",
      "|    total_timesteps      | 81664       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003663719 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.215      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 6370        |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 54        |\n",
      "|    iterations           | 639       |\n",
      "|    time_elapsed         | 1492      |\n",
      "|    total_timesteps      | 81792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0137264 |\n",
      "|    clip_fraction        | 0.0875    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.218    |\n",
      "|    explained_variance   | 0.965     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 74        |\n",
      "|    n_updates            | 6380      |\n",
      "|    policy_gradient_loss | -0.00778  |\n",
      "|    value_loss           | 157       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 640         |\n",
      "|    time_elapsed         | 1494        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017036516 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.235      |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 376         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=82000, episode_reward=89.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 89.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 82000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042840177 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.177       |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 259          |\n",
      "|    n_updates            | 6400         |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 530          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 641   |\n",
      "|    time_elapsed    | 1497  |\n",
      "|    total_timesteps | 82048 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 1499        |\n",
      "|    total_timesteps      | 82176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006275021 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.18       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    value_loss           | 499         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 643          |\n",
      "|    time_elapsed         | 1502         |\n",
      "|    total_timesteps      | 82304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035052756 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.196       |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 229          |\n",
      "|    n_updates            | 6420         |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    value_loss           | 474          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 1504        |\n",
      "|    total_timesteps      | 82432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014261289 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    value_loss           | 435         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=82500, episode_reward=95.95 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 95.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 82500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084676165 |\n",
      "|    clip_fraction        | 0.0656       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.226       |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 214          |\n",
      "|    n_updates            | 6440         |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    value_loss           | 431          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 645   |\n",
      "|    time_elapsed    | 1506  |\n",
      "|    total_timesteps | 82560 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 646          |\n",
      "|    time_elapsed         | 1508         |\n",
      "|    total_timesteps      | 82688        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049769985 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 200          |\n",
      "|    n_updates            | 6450         |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    value_loss           | 403          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 1511        |\n",
      "|    total_timesteps      | 82816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009224791 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.22       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 648          |\n",
      "|    time_elapsed         | 1513         |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047517167 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 192          |\n",
      "|    n_updates            | 6470         |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    value_loss           | 387          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=83000, episode_reward=67.00 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 67          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 83000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021574065 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.22       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.1        |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 649   |\n",
      "|    time_elapsed    | 1516  |\n",
      "|    total_timesteps | 83072 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 650         |\n",
      "|    time_elapsed         | 1519        |\n",
      "|    total_timesteps      | 83200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015058464 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.213      |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71          |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 651          |\n",
      "|    time_elapsed         | 1521         |\n",
      "|    total_timesteps      | 83328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026643283 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.16        |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 6500         |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    value_loss           | 378          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 1524        |\n",
      "|    total_timesteps      | 83456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003036042 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.15       |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    value_loss           | 371         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=83500, episode_reward=57.20 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 57.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 83500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010101493 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.172      |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 376         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 653   |\n",
      "|    time_elapsed    | 1526  |\n",
      "|    total_timesteps | 83584 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 654          |\n",
      "|    time_elapsed         | 1529         |\n",
      "|    total_timesteps      | 83712        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071227993 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 198          |\n",
      "|    n_updates            | 6530         |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    value_loss           | 400          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 655          |\n",
      "|    time_elapsed         | 1531         |\n",
      "|    total_timesteps      | 83840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027948967 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.206       |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 6540         |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    value_loss           | 424          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 1533        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006276096 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.191      |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    value_loss           | 375         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=84000, episode_reward=83.50 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 83.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 84000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031603593 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.214       |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 6560         |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    value_loss           | 362          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 657   |\n",
      "|    time_elapsed    | 1535  |\n",
      "|    total_timesteps | 84096 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 1537        |\n",
      "|    total_timesteps      | 84224       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003960224 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.221      |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 392         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 659          |\n",
      "|    time_elapsed         | 1540         |\n",
      "|    total_timesteps      | 84352        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041822223 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.219       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 94.6         |\n",
      "|    n_updates            | 6580         |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    value_loss           | 196          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 660        |\n",
      "|    time_elapsed         | 1543       |\n",
      "|    total_timesteps      | 84480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03402085 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.214     |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 67.8       |\n",
      "|    n_updates            | 6590       |\n",
      "|    policy_gradient_loss | -0.00632   |\n",
      "|    value_loss           | 139        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=84500, episode_reward=84.40 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 84.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 84500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025468424 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.175      |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 380         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 661   |\n",
      "|    time_elapsed    | 1545  |\n",
      "|    total_timesteps | 84608 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 1547        |\n",
      "|    total_timesteps      | 84736       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004346306 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.164      |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 234         |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 472         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 1550        |\n",
      "|    total_timesteps      | 84864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027643396 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.179      |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    value_loss           | 325         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 664          |\n",
      "|    time_elapsed         | 1552         |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010762031 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.22        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 222          |\n",
      "|    n_updates            | 6630         |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 450          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=83.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 83          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 85000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008369778 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    value_loss           | 428         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 665   |\n",
      "|    time_elapsed    | 1554  |\n",
      "|    total_timesteps | 85120 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 1556        |\n",
      "|    total_timesteps      | 85248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004097012 |\n",
      "|    clip_fraction        | 0.00703     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.223      |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 404         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 667          |\n",
      "|    time_elapsed         | 1558         |\n",
      "|    total_timesteps      | 85376        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056871716 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.233       |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 178          |\n",
      "|    n_updates            | 6660         |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 358          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=85500, episode_reward=86.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 86.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 85500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013575216 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.245       |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 173          |\n",
      "|    n_updates            | 6670         |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    value_loss           | 350          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 668   |\n",
      "|    time_elapsed    | 1561  |\n",
      "|    total_timesteps | 85504 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 669         |\n",
      "|    time_elapsed         | 1564        |\n",
      "|    total_timesteps      | 85632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028039923 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.239      |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.6        |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 1566        |\n",
      "|    total_timesteps      | 85760       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024105955 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.1        |\n",
      "|    n_updates            | 6690        |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 671          |\n",
      "|    time_elapsed         | 1568         |\n",
      "|    total_timesteps      | 85888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029531168 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.225       |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 176          |\n",
      "|    n_updates            | 6700         |\n",
      "|    policy_gradient_loss | -0.000366    |\n",
      "|    value_loss           | 356          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=86000, episode_reward=86.30 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 86.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 86000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004071299 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.192      |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 214         |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    value_loss           | 432         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 672   |\n",
      "|    time_elapsed    | 1571  |\n",
      "|    total_timesteps | 86016 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 673          |\n",
      "|    time_elapsed         | 1574         |\n",
      "|    total_timesteps      | 86144        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051945117 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 216          |\n",
      "|    n_updates            | 6720         |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 435          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 674         |\n",
      "|    time_elapsed         | 1576        |\n",
      "|    total_timesteps      | 86272       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018671565 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.221      |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    value_loss           | 447         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 675          |\n",
      "|    time_elapsed         | 1578         |\n",
      "|    total_timesteps      | 86400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076459446 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.249       |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 225          |\n",
      "|    n_updates            | 6740         |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    value_loss           | 458          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=86500, episode_reward=84.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 84.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 86500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054874416 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.242       |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 211          |\n",
      "|    n_updates            | 6750         |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    value_loss           | 425          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 676   |\n",
      "|    time_elapsed    | 1581  |\n",
      "|    total_timesteps | 86528 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 677          |\n",
      "|    time_elapsed         | 1582         |\n",
      "|    total_timesteps      | 86656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016341505 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.233       |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 216          |\n",
      "|    n_updates            | 6760         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 437          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 678          |\n",
      "|    time_elapsed         | 1585         |\n",
      "|    total_timesteps      | 86784        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043853913 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.263       |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 163          |\n",
      "|    n_updates            | 6770         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    value_loss           | 330          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 1587        |\n",
      "|    total_timesteps      | 86912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013022267 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=87000, episode_reward=87.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 87           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 87000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031892348 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.253       |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 49.3         |\n",
      "|    n_updates            | 6790         |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 680   |\n",
      "|    time_elapsed    | 1590  |\n",
      "|    total_timesteps | 87040 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 681          |\n",
      "|    time_elapsed         | 1592         |\n",
      "|    total_timesteps      | 87168        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013068728 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.233       |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 6800         |\n",
      "|    policy_gradient_loss | -0.000864    |\n",
      "|    value_loss           | 273          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 682          |\n",
      "|    time_elapsed         | 1594         |\n",
      "|    total_timesteps      | 87296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035730556 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.194       |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 190          |\n",
      "|    n_updates            | 6810         |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 391          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 683          |\n",
      "|    time_elapsed         | 1597         |\n",
      "|    total_timesteps      | 87424        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018588828 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.193       |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 6820         |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 365          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=87500, episode_reward=87.30 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 87.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 87500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034990169 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.21        |\n",
      "|    explained_variance   | 0.923        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 176          |\n",
      "|    n_updates            | 6830         |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    value_loss           | 363          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 684   |\n",
      "|    time_elapsed    | 1599  |\n",
      "|    total_timesteps | 87552 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 1601        |\n",
      "|    total_timesteps      | 87680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009740034 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    value_loss           | 382         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 686          |\n",
      "|    time_elapsed         | 1603         |\n",
      "|    total_timesteps      | 87808        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066747665 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.243       |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 167          |\n",
      "|    n_updates            | 6850         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    value_loss           | 337          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 1605        |\n",
      "|    total_timesteps      | 87936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002447832 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.232      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 181         |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=88000, episode_reward=95.95 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 95.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 88000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005505885 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    value_loss           | 321         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 688   |\n",
      "|    time_elapsed    | 1608  |\n",
      "|    total_timesteps | 88064 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 689         |\n",
      "|    time_elapsed         | 1610        |\n",
      "|    total_timesteps      | 88192       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014712613 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    value_loss           | 252         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 1612        |\n",
      "|    total_timesteps      | 88320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009191413 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.5        |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 691          |\n",
      "|    time_elapsed         | 1614         |\n",
      "|    total_timesteps      | 88448        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019578482 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.241       |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 6900         |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    value_loss           | 222          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=88500, episode_reward=93.05 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 88         |\n",
      "|    mean_reward          | 93         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 88500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02512854 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.198     |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 196        |\n",
      "|    n_updates            | 6910       |\n",
      "|    policy_gradient_loss | -0.00804   |\n",
      "|    value_loss           | 396        |\n",
      "----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 692   |\n",
      "|    time_elapsed    | 1617  |\n",
      "|    total_timesteps | 88576 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 693          |\n",
      "|    time_elapsed         | 1620         |\n",
      "|    total_timesteps      | 88704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038628983 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 204          |\n",
      "|    n_updates            | 6920         |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    value_loss           | 418          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 694         |\n",
      "|    time_elapsed         | 1622        |\n",
      "|    total_timesteps      | 88832       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005781171 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.209      |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 695          |\n",
      "|    time_elapsed         | 1624         |\n",
      "|    total_timesteps      | 88960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018910735 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.234       |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 180          |\n",
      "|    n_updates            | 6940         |\n",
      "|    policy_gradient_loss | -0.00034     |\n",
      "|    value_loss           | 364          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=89000, episode_reward=72.40 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 72.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 89000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066996347 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.211       |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 6950         |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    value_loss           | 363          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 696   |\n",
      "|    time_elapsed    | 1627  |\n",
      "|    total_timesteps | 89088 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 697          |\n",
      "|    time_elapsed         | 1629         |\n",
      "|    total_timesteps      | 89216        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061579994 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.172       |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 176          |\n",
      "|    n_updates            | 6960         |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 355          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 1631        |\n",
      "|    total_timesteps      | 89344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003900719 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.204      |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    value_loss           | 387         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 699          |\n",
      "|    time_elapsed         | 1633         |\n",
      "|    total_timesteps      | 89472        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066800825 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 80.6         |\n",
      "|    n_updates            | 6980         |\n",
      "|    policy_gradient_loss | -0.00788     |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=89500, episode_reward=78.10 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 78.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 89500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014282232 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.8        |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 700   |\n",
      "|    time_elapsed    | 1636  |\n",
      "|    total_timesteps | 89600 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 1638        |\n",
      "|    total_timesteps      | 89728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005631945 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.235      |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.6        |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 1641        |\n",
      "|    total_timesteps      | 89856       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004422283 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.172      |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 367         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 703          |\n",
      "|    time_elapsed         | 1643         |\n",
      "|    total_timesteps      | 89984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038358679 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.171       |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 174          |\n",
      "|    n_updates            | 7020         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 349          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=60.35 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 60.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 90000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025308838 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.172       |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 171          |\n",
      "|    n_updates            | 7030         |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    value_loss           | 349          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 704   |\n",
      "|    time_elapsed    | 1646  |\n",
      "|    total_timesteps | 90112 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 705          |\n",
      "|    time_elapsed         | 1648         |\n",
      "|    total_timesteps      | 90240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014538537 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 7040         |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 332          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 1650        |\n",
      "|    total_timesteps      | 90368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010546045 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.206      |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    value_loss           | 331         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 707          |\n",
      "|    time_elapsed         | 1652         |\n",
      "|    total_timesteps      | 90496        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059688943 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.19        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 7060         |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    value_loss           | 331          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=90500, episode_reward=67.60 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 67.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 90500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010534511 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.2         |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 7070         |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    value_loss           | 349          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 708   |\n",
      "|    time_elapsed    | 1654  |\n",
      "|    total_timesteps | 90624 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 709          |\n",
      "|    time_elapsed         | 1657         |\n",
      "|    total_timesteps      | 90752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029043078 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.212       |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 7080         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 219          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 1660        |\n",
      "|    total_timesteps      | 90880       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004699138 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.219      |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.8        |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    value_loss           | 92          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=91000, episode_reward=86.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 88         |\n",
      "|    mean_reward          | 86.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 91000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01302336 |\n",
      "|    clip_fraction        | 0.0563     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.23      |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 57.7       |\n",
      "|    n_updates            | 7100       |\n",
      "|    policy_gradient_loss | -0.00407   |\n",
      "|    value_loss           | 122        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 711   |\n",
      "|    time_elapsed    | 1662  |\n",
      "|    total_timesteps | 91008 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 1665        |\n",
      "|    total_timesteps      | 91136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011066994 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.184      |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 179         |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    value_loss           | 365         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 713         |\n",
      "|    time_elapsed         | 1668        |\n",
      "|    total_timesteps      | 91264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014352379 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.177      |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    value_loss           | 390         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 714          |\n",
      "|    time_elapsed         | 1670         |\n",
      "|    total_timesteps      | 91392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015852107 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.189       |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 185          |\n",
      "|    n_updates            | 7130         |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    value_loss           | 376          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=91500, episode_reward=84.55 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 84.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 91500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126898885 |\n",
      "|    clip_fraction        | 0.0656       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.212       |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 168          |\n",
      "|    n_updates            | 7140         |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    value_loss           | 339          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 715   |\n",
      "|    time_elapsed    | 1672  |\n",
      "|    total_timesteps | 91520 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 716        |\n",
      "|    time_elapsed         | 1674       |\n",
      "|    total_timesteps      | 91648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00664129 |\n",
      "|    clip_fraction        | 0.0367     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.222     |\n",
      "|    explained_variance   | 0.944      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 178        |\n",
      "|    n_updates            | 7150       |\n",
      "|    policy_gradient_loss | -0.00268   |\n",
      "|    value_loss           | 363        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 717          |\n",
      "|    time_elapsed         | 1676         |\n",
      "|    total_timesteps      | 91776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019849616 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.21        |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 7160         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 379          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 718         |\n",
      "|    time_elapsed         | 1678        |\n",
      "|    total_timesteps      | 91904       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011841007 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.228      |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 175         |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    value_loss           | 358         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=92000, episode_reward=94.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 94.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 92000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007285158 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.242      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    value_loss           | 365         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 719   |\n",
      "|    time_elapsed    | 1681  |\n",
      "|    total_timesteps | 92032 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 1683        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003893135 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 90          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 721          |\n",
      "|    time_elapsed         | 1686         |\n",
      "|    total_timesteps      | 92288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026333856 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.239       |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 55.4         |\n",
      "|    n_updates            | 7200         |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 722          |\n",
      "|    time_elapsed         | 1688         |\n",
      "|    total_timesteps      | 92416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108658075 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.19        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 167          |\n",
      "|    n_updates            | 7210         |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    value_loss           | 336          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=92500, episode_reward=92.45 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 92.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 92500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017018712 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.165       |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 143          |\n",
      "|    n_updates            | 7220         |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    value_loss           | 294          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 723   |\n",
      "|    time_elapsed    | 1691  |\n",
      "|    total_timesteps | 92544 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 724          |\n",
      "|    time_elapsed         | 1693         |\n",
      "|    total_timesteps      | 92672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017986435 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.188       |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 178          |\n",
      "|    n_updates            | 7230         |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    value_loss           | 359          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 725          |\n",
      "|    time_elapsed         | 1695         |\n",
      "|    total_timesteps      | 92800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024645336 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.212       |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 7240         |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 347          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 726          |\n",
      "|    time_elapsed         | 1697         |\n",
      "|    total_timesteps      | 92928        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014302824 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.211       |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 177          |\n",
      "|    n_updates            | 7250         |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    value_loss           | 360          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=93000, episode_reward=82.70 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 82.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 93000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069979974 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.18        |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 177          |\n",
      "|    n_updates            | 7260         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 363          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 727   |\n",
      "|    time_elapsed    | 1700  |\n",
      "|    total_timesteps | 93056 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 1702        |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015894515 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.197      |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 1704        |\n",
      "|    total_timesteps      | 93312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016603881 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.235      |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 166         |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    value_loss           | 337         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 1707        |\n",
      "|    total_timesteps      | 93440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005083791 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.246      |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91          |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=93500, episode_reward=83.85 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 83.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 93500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023139125 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 731   |\n",
      "|    time_elapsed    | 1710  |\n",
      "|    total_timesteps | 93568 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 732           |\n",
      "|    time_elapsed         | 1712          |\n",
      "|    total_timesteps      | 93696         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015317509 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.205        |\n",
      "|    explained_variance   | 0.938         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 160           |\n",
      "|    n_updates            | 7310          |\n",
      "|    policy_gradient_loss | -0.00011      |\n",
      "|    value_loss           | 320           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 733         |\n",
      "|    time_elapsed         | 1714        |\n",
      "|    total_timesteps      | 93824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008306277 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.166      |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    value_loss           | 292         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 734          |\n",
      "|    time_elapsed         | 1717         |\n",
      "|    total_timesteps      | 93952        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068902695 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.181       |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 181          |\n",
      "|    n_updates            | 7330         |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    value_loss           | 364          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=94000, episode_reward=87.70 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 87.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 94000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005736398 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.225      |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    value_loss           | 355         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 735   |\n",
      "|    time_elapsed    | 1719  |\n",
      "|    total_timesteps | 94080 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 1721        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010801948 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.228      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 7350        |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    value_loss           | 395         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 737          |\n",
      "|    time_elapsed         | 1723         |\n",
      "|    total_timesteps      | 94336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003620442 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.21        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 174          |\n",
      "|    n_updates            | 7360         |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    value_loss           | 351          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 1725        |\n",
      "|    total_timesteps      | 94464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002618994 |\n",
      "|    clip_fraction        | 0.00703     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.206      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    value_loss           | 316         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=94500, episode_reward=91.70 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 91.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 94500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017346127 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    value_loss           | 317         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 739   |\n",
      "|    time_elapsed    | 1728  |\n",
      "|    total_timesteps | 94592 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 1730         |\n",
      "|    total_timesteps      | 94720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034552661 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.239       |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 79.7         |\n",
      "|    n_updates            | 7390         |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 741          |\n",
      "|    time_elapsed         | 1733         |\n",
      "|    total_timesteps      | 94848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010977248 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.241       |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.6         |\n",
      "|    n_updates            | 7400         |\n",
      "|    policy_gradient_loss | -0.000306    |\n",
      "|    value_loss           | 72.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 1735        |\n",
      "|    total_timesteps      | 94976       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008488312 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.208      |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    value_loss           | 282         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=88.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 88.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 95000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010448326 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 7420         |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 334          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 743   |\n",
      "|    time_elapsed    | 1738  |\n",
      "|    total_timesteps | 95104 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 744          |\n",
      "|    time_elapsed         | 1740         |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057469183 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.184       |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 7430         |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 330          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 1742        |\n",
      "|    total_timesteps      | 95360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008189671 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.208      |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 746          |\n",
      "|    time_elapsed         | 1744         |\n",
      "|    total_timesteps      | 95488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043860944 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.225       |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 157          |\n",
      "|    n_updates            | 7450         |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    value_loss           | 317          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=95500, episode_reward=61.50 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 61.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 95500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005442564 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.214      |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    value_loss           | 312         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 747   |\n",
      "|    time_elapsed    | 1747  |\n",
      "|    total_timesteps | 95616 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 748          |\n",
      "|    time_elapsed         | 1749         |\n",
      "|    total_timesteps      | 95744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032588562 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.208       |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 161          |\n",
      "|    n_updates            | 7470         |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    value_loss           | 327          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 749          |\n",
      "|    time_elapsed         | 1751         |\n",
      "|    total_timesteps      | 95872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067999586 |\n",
      "|    clip_fraction        | 0.0547       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.239       |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 152          |\n",
      "|    n_updates            | 7480         |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    value_loss           | 316          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=64.30 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 64.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100084655 |\n",
      "|    clip_fraction        | 0.068        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.228       |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 76.9         |\n",
      "|    n_updates            | 7490         |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 750   |\n",
      "|    time_elapsed    | 1753  |\n",
      "|    total_timesteps | 96000 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 1756        |\n",
      "|    total_timesteps      | 96128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005867048 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 752          |\n",
      "|    time_elapsed         | 1758         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058780373 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.199       |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 7510         |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 251          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 1761        |\n",
      "|    total_timesteps      | 96384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009152217 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.152      |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=96500, episode_reward=91.40 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 91.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 96500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018969642 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.171      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 754   |\n",
      "|    time_elapsed    | 1763  |\n",
      "|    total_timesteps | 96512 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 755          |\n",
      "|    time_elapsed         | 1765         |\n",
      "|    total_timesteps      | 96640        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060110684 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 162          |\n",
      "|    n_updates            | 7540         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 331          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 1767        |\n",
      "|    total_timesteps      | 96768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012992617 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 757         |\n",
      "|    time_elapsed         | 1769        |\n",
      "|    total_timesteps      | 96896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020081561 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.211      |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 7560        |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    value_loss           | 321         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=97000, episode_reward=73.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 73.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 97000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035561104 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.187       |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 7570         |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    value_loss           | 325          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 758   |\n",
      "|    time_elapsed    | 1771  |\n",
      "|    total_timesteps | 97024 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 759          |\n",
      "|    time_elapsed         | 1773         |\n",
      "|    total_timesteps      | 97152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115113165 |\n",
      "|    clip_fraction        | 0.0672       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.222       |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 170          |\n",
      "|    n_updates            | 7580         |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    value_loss           | 357          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 1776        |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012371977 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.231      |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 761          |\n",
      "|    time_elapsed         | 1779         |\n",
      "|    total_timesteps      | 97408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039575784 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.241       |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 54.3         |\n",
      "|    n_updates            | 7600         |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=97500, episode_reward=79.90 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 79.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 97500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053317053 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.225       |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 64.2         |\n",
      "|    n_updates            | 7610         |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 762   |\n",
      "|    time_elapsed    | 1781  |\n",
      "|    total_timesteps | 97536 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 1784        |\n",
      "|    total_timesteps      | 97664       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019571379 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.181      |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 179         |\n",
      "|    n_updates            | 7620        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    value_loss           | 365         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 764        |\n",
      "|    time_elapsed         | 1786       |\n",
      "|    total_timesteps      | 97792      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00662914 |\n",
      "|    clip_fraction        | 0.0266     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.173     |\n",
      "|    explained_variance   | 0.932      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 152        |\n",
      "|    n_updates            | 7630       |\n",
      "|    policy_gradient_loss | -0.0045    |\n",
      "|    value_loss           | 310        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 765         |\n",
      "|    time_elapsed         | 1789        |\n",
      "|    total_timesteps      | 97920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010241468 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.194      |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    value_loss           | 333         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=98000, episode_reward=79.25 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 79.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 98000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068559363 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.216       |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 7650         |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    value_loss           | 312          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 766   |\n",
      "|    time_elapsed    | 1791  |\n",
      "|    total_timesteps | 98048 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 767          |\n",
      "|    time_elapsed         | 1793         |\n",
      "|    total_timesteps      | 98176        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053180372 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.212       |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 7660         |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 343          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 768          |\n",
      "|    time_elapsed         | 1795         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004039856 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.198       |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 162          |\n",
      "|    n_updates            | 7670         |\n",
      "|    policy_gradient_loss | -0.000992    |\n",
      "|    value_loss           | 329          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 1797        |\n",
      "|    total_timesteps      | 98432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008993852 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 376         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=98500, episode_reward=91.50 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 91.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 98500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070440415 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.232       |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 7690         |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 770   |\n",
      "|    time_elapsed    | 1800  |\n",
      "|    total_timesteps | 98560 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 771          |\n",
      "|    time_elapsed         | 1802         |\n",
      "|    total_timesteps      | 98688        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059862686 |\n",
      "|    clip_fraction        | 0.0594       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.233       |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 7700         |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 772          |\n",
      "|    time_elapsed         | 1804         |\n",
      "|    total_timesteps      | 98816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056768414 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.218       |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 65.8         |\n",
      "|    n_updates            | 7710         |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 1807        |\n",
      "|    total_timesteps      | 98944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011932844 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.169      |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    value_loss           | 309         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=99000, episode_reward=91.50 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 91.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 99000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003187011 |\n",
      "|    clip_fraction        | 0.00703     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.161      |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 320         |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 774   |\n",
      "|    time_elapsed    | 1810  |\n",
      "|    total_timesteps | 99072 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 775          |\n",
      "|    time_elapsed         | 1812         |\n",
      "|    total_timesteps      | 99200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032438582 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.184       |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 161          |\n",
      "|    n_updates            | 7740         |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    value_loss           | 329          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 776          |\n",
      "|    time_elapsed         | 1815         |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013764203 |\n",
      "|    clip_fraction        | 0.0602       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.218       |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 7750         |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 312          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 777         |\n",
      "|    time_elapsed         | 1817        |\n",
      "|    total_timesteps      | 99456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003915343 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 7760        |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    value_loss           | 326         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=99500, episode_reward=82.80 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88           |\n",
      "|    mean_reward          | 82.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 99500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016128386 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.212       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 7770         |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    value_loss           | 316          |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 54    |\n",
      "|    iterations      | 778   |\n",
      "|    time_elapsed    | 1819  |\n",
      "|    total_timesteps | 99584 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 779          |\n",
      "|    time_elapsed         | 1821         |\n",
      "|    total_timesteps      | 99712        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020721108 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.223       |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 162          |\n",
      "|    n_updates            | 7780         |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 325          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 1823        |\n",
      "|    total_timesteps      | 99840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004846595 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 224         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 781          |\n",
      "|    time_elapsed         | 1826         |\n",
      "|    total_timesteps      | 99968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010985171 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.227       |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 7800         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=100000, episode_reward=86.65 +/- 0.00\n",
      "Episode length: 88.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88          |\n",
      "|    mean_reward          | 86.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004347522 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54          |\n",
      "|    n_updates            | 7810        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 54     |\n",
      "|    iterations      | 782    |\n",
      "|    time_elapsed    | 1828   |\n",
      "|    total_timesteps | 100096 |\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_recurrent.ppo_recurrent.RecurrentPPO at 0x2304e0b02e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "# Separate evaluation env\n",
    "eval_env = MyStocksEnv(df=df, frame_bound=(151,240), window_size = 7)\n",
    "k = lambda: eval_env\n",
    "eval_env = DummyVecEnv([k])\n",
    "\n",
    "#creating the evaluation callback and using evaluation enviroment for evaluating the model\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=\"./logs/\",\n",
    "                             log_path=\"logs/\", eval_freq=500,\n",
    "                             deterministic=True, render=False)\n",
    "\n",
    "#using the lstm policy since each record is depended on previous records\n",
    "model = RecurrentPPO(\"MlpLstmPolicy\",env, verbose=1,device='cuda:0')\n",
    "model.learn(total_timesteps=100000,callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a2f0ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-41129d5f2ef4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "env = MyStocksEnv(df=df, frame_bound=(210,249), window_size = 7)\n",
    "state = env.reset()\n",
    "while True:\n",
    "    state = state[np.newaxis, ...]\n",
    "    action, _states = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        print('Info:',info)\n",
    "        print('Profit:',str((info['total_profit']-1)*100)+'%')\n",
    "        break\n",
    "        \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40528f4b",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3578909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6170935",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2225af9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4141311aaf18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dqn_stock\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"dqn_stock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adbf96d",
   "metadata": {},
   "source": [
    "# Loading the model and testing it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4562bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = RecurrentPPO.load('dqn_stock',env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04f444ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: {'total_reward': 22.30000000000001, 'total_profit': 0.9780114663952567, 'position': 0}\n",
      "Profit: -2.1988533604743288%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    n_state, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        print('Info:',info)\n",
    "        print('Profit:',str((info['total_profit']-1)*100)+'%')\n",
    "        break\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
